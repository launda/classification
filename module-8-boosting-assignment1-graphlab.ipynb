{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Ensemble Methods\n",
    "## Module 8 Boosting Assignment1 graphlab ver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will explore the use of boosting. We will use the pre-implemented gradient boosted trees in GraphLab Create. You will:\n",
    "\n",
    "* Use SFrames to do some feature engineering.\n",
    "* Train a boosted ensemble of decision-trees (gradient boosted trees) on the LendingClub dataset.\n",
    "* Predict whether a loan will default along with prediction probabilities (on a validation set).\n",
    "* Evaluate the trained model and compare it with a baseline.\n",
    "* Find the most positive and negative loans using the learned model.\n",
    "* Explore how the number of trees influences classification performance.\n",
    "\n",
    "\n",
    "## Fire up pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import libraries:\n",
    "import graphlab\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LendingClub dataset\n",
    "\n",
    "We will be using the [LendingClub](https://www.lendingclub.com/) data. As discussed earlier, the [LendingClub](https://www.lendingclub.com/) is a peer-to-peer leading company that directly connects borrowers and potential lenders/investors. \n",
    "\n",
    "Just like we did in previous assignments, we will build a classification model to predict whether or not a loan provided by lending club is likely to default.\n",
    "\n",
    "**1.** Loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loans = graphlab.SFrame('../Week3/lending-club-data.gl/')\n",
    "#loans = pd.read_csv('../Week3/lending-club-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Let's quickly explore what the dataset looks like. First, let's print out the column names to see what features we have in this dataset. We have done this in previous assignments, so we won't belabor this here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'member_id',\n",
       " 'loan_amnt',\n",
       " 'funded_amnt',\n",
       " 'funded_amnt_inv',\n",
       " 'term',\n",
       " 'int_rate',\n",
       " 'installment',\n",
       " 'grade',\n",
       " 'sub_grade',\n",
       " 'emp_title',\n",
       " 'emp_length',\n",
       " 'home_ownership',\n",
       " 'annual_inc',\n",
       " 'is_inc_v',\n",
       " 'issue_d',\n",
       " 'loan_status',\n",
       " 'pymnt_plan',\n",
       " 'url',\n",
       " 'desc',\n",
       " 'purpose',\n",
       " 'title',\n",
       " 'zip_code',\n",
       " 'addr_state',\n",
       " 'dti',\n",
       " 'delinq_2yrs',\n",
       " 'earliest_cr_line',\n",
       " 'inq_last_6mths',\n",
       " 'mths_since_last_delinq',\n",
       " 'mths_since_last_record',\n",
       " 'open_acc',\n",
       " 'pub_rec',\n",
       " 'revol_bal',\n",
       " 'revol_util',\n",
       " 'total_acc',\n",
       " 'initial_list_status',\n",
       " 'out_prncp',\n",
       " 'out_prncp_inv',\n",
       " 'total_pymnt',\n",
       " 'total_pymnt_inv',\n",
       " 'total_rec_prncp',\n",
       " 'total_rec_int',\n",
       " 'total_rec_late_fee',\n",
       " 'recoveries',\n",
       " 'collection_recovery_fee',\n",
       " 'last_pymnt_d',\n",
       " 'last_pymnt_amnt',\n",
       " 'next_pymnt_d',\n",
       " 'last_credit_pull_d',\n",
       " 'collections_12_mths_ex_med',\n",
       " 'mths_since_last_major_derog',\n",
       " 'policy_code',\n",
       " 'not_compliant',\n",
       " 'status',\n",
       " 'inactive_loans',\n",
       " 'bad_loans',\n",
       " 'emp_length_num',\n",
       " 'grade_num',\n",
       " 'sub_grade_num',\n",
       " 'delinq_2yrs_zero',\n",
       " 'pub_rec_zero',\n",
       " 'collections_12_mths_zero',\n",
       " 'short_emp',\n",
       " 'payment_inc_ratio',\n",
       " 'final_d',\n",
       " 'last_delinq_none',\n",
       " 'last_record_none',\n",
       " 'last_major_derog_none']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(loans)\n",
    "loans.column_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the target column\n",
    "\n",
    "**3.** The target column (label column) of the dataset that we are interested in is called `bad_loans`. In this column **1** means a risky (bad) loan **0** means a safe  loan.\n",
    "\n",
    "As in past assignments, in order to make this more intuitive and consistent with the lectures, we reassign the target to be:\n",
    "* **+1** as a safe  loan, \n",
    "* **-1** as a risky (bad) loan. \n",
    "\n",
    "We put this in a new column called `safe_loans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------+-----------+------------+\n",
      "|    id   | member_id | loan_amnt | bad_loans | safe_loans |\n",
      "+---------+-----------+-----------+-----------+------------+\n",
      "| 1077501 |  1296599  |    5000   |     0     |     1      |\n",
      "| 1077430 |  1314167  |    2500   |     1     |     -1     |\n",
      "+---------+-----------+-----------+-----------+------------+\n",
      "[2 rows x 5 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "\n",
    "# safe_loans =  1 => safe\n",
    "# safe_loans = -1 => risky\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "\n",
    "# just check if conversion done properly, before removing the 'bad_loans' col\n",
    "print loans[['id', 'member_id', 'loan_amnt', 'bad_loans', 'safe_loans']].head(2)\n",
    "\n",
    "# removing row traightforward\n",
    "# to remove/drop a column, axis=1 denotes that we are referring to a column\n",
    "# see http://chrisalbon.com/python/pandas_dropping_column_and_rows.html\n",
    "\n",
    "loans = loans.remove_column('bad_loans')\n",
    "#loans = loans.drop('bad_loans', axis=1)   #pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features\n",
    "\n",
    "**4.** In this assignment, we will be using a subset of features (categorical and numeric). The features we will be using are **described in the code comments** below. If you are a finance geek, the [LendingClub](https://www.lendingclub.com/) website has a lot more details about these features.\n",
    "\n",
    "The features we will be using are described in the code comments below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grade', 'sub_grade_num', 'short_emp', 'emp_length_num', 'home_ownership', 'dti', 'purpose', 'payment_inc_ratio', 'delinq_2yrs', 'delinq_2yrs_zero', 'inq_last_6mths', 'last_delinq_none', 'last_major_derog_none', 'open_acc', 'pub_rec', 'pub_rec_zero', 'revol_util', 'total_rec_late_fee', 'int_rate', 'total_rec_int', 'annual_inc', 'funded_amnt', 'funded_amnt_inv', 'installment']\n",
      "122607\n"
     ]
    }
   ],
   "source": [
    "target = 'safe_loans'\n",
    "features = ['grade',                     # grade of the loan (categorical)\n",
    "            'sub_grade_num',             # sub-grade of the loan as a number from 0 to 1\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'dti',                       # debt to income ratio\n",
    "            'purpose',                   # the purpose of the loan\n",
    "            'payment_inc_ratio',         # ratio of the monthly payment to income\n",
    "            'delinq_2yrs',               # number of delinquincies \n",
    "            'delinq_2yrs_zero',          # no delinquincies in last 2 years\n",
    "            'inq_last_6mths',            # number of creditor inquiries in last 6 months\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "            'open_acc',                  # number of open credit accounts\n",
    "            'pub_rec',                   # number of derogatory public records\n",
    "            'pub_rec_zero',              # no derogatory public records\n",
    "            'revol_util',                # percent of available credit being used\n",
    "            'total_rec_late_fee',        # total late fees received to day\n",
    "            'int_rate',                  # interest rate of the loan\n",
    "            'total_rec_int',             # interest received to date\n",
    "            'annual_inc',                # annual income of borrower\n",
    "            'funded_amnt',               # amount committed to the loan\n",
    "            'funded_amnt_inv',           # amount committed by investors for the loan\n",
    "            'installment',               # monthly payment owed by the borrower\n",
    "           ]\n",
    "\n",
    "#loans = loans[features + [target]]\n",
    "\n",
    "print features\n",
    "print len(loans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipping observations with missing values\n",
    "\n",
    "**5.** Recall from the lectures that one common approach to coping with missing values is to **skip** observations that contain missing values.\n",
    "\n",
    "Fortunately, there are not too many missing values. We are retaining most of the data.\n",
    "\n",
    "Your tool may provide a function to skip observations with missing values. Consult appropriate manuals.\n",
    "\n",
    "Fortunately, as you should find, there are not too many missing values. We are retaining most of the data.\n",
    "Notes to people using other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 29 observations; keeping 122578 \n",
      "122578\n"
     ]
    }
   ],
   "source": [
    "loans, loans_with_na = loans[[target] + features].dropna_split()\n",
    "\n",
    "# Count the number of rows with missing data\n",
    "num_rows_with_na = loans_with_na.num_rows()\n",
    "num_rows = loans.num_rows()\n",
    "print 'Dropping %s observations; keeping %s ' % (num_rows_with_na, num_rows)\n",
    "# Dropping 29 observations; keeping 122578 \n",
    "\n",
    "# loans = loans[[target] + features].dropna()  #pandas\n",
    "\n",
    "print len(loans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using SFrame, proceed to the section \"Make sure the classes are balanced\". Else go to NOT using SFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure the classes are balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** We saw in an earlier assignment that this dataset is also imbalanced. We will undersample the larger class (safe loans) in order to balance out our dataset. We used `seed=1` to make sure everyone gets the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of safe loans                 : 0.502247166849\n",
      "Percentage of risky loans                : 0.497752833151\n",
      "Total number of loans in our new dataset : 46503\n"
     ]
    }
   ],
   "source": [
    "safe_loans_raw = loans[loans[target] == 1]\n",
    "risky_loans_raw = loans[loans[target] == -1]\n",
    "\n",
    "# Undersample the safe loans.\n",
    "percentage = len(risky_loans_raw)/float(len(safe_loans_raw))\n",
    "safe_loans = safe_loans_raw.sample(percentage, seed = 1)\n",
    "risky_loans = risky_loans_raw\n",
    "loans_data = risky_loans.append(safe_loans)\n",
    "\n",
    "print \"Percentage of safe loans                 :\", len(safe_loans) / float(len(loans_data))\n",
    "print \"Percentage of risky loans                :\", len(risky_loans) / float(len(loans_data))\n",
    "print \"Total number of loans in our new dataset :\", len(loans_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** You should now see that the dataset is balanced (approximately 50-50 safe vs risky loans)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** There are many approaches for dealing with imbalanced data, including some where we modify the learning algorithm. These approaches are beyond the scope of this course, but some of them are reviewed in in \"[Learning from Imbalanced Data](http://www.ele.uri.edu/faculty/he/PDFfiles/ImbalancedLearning.pdf)\" by Haibo He and Edwardo A. Garcia, *IEEE Transactions on Knowledge and Data Engineering* **21**(9) (June 26, 2009), p. 1263â€“1284. For this assignment, we use the simplest possible approach, where we subsample the overly represented class to get a more balanced dataset. In general, and especially when the data is highly imbalanced, we recommend using more advanced methods.\n",
    "\n",
    "\n",
    "Attempting to learn from imbalanced data is difficult; namely, that assessing the performance of a classifier trained on an imbalanced dataset is more difficult. A real-world email dataset is likely to be imbalanced because approximately 90% of all email sent is spam. The so-called majority class classifier which labels all email as spam would therefore have ~90% accuracy on a representative test dataset. Overall accuracy or error of a spam email classifier does not provide adequate information for evaluation purposes because of this imbalance. We would need to look at other assessment metrics such as precision-recall curves for more conclusive evaluation of a classifier's performance.\n",
    "\n",
    "Bit like in fog forecasting, fog only occurs 2% of days in a year, so if we forecast no fog every time, we will be correct 98% of the time. Although this is very high accuracy, it does not provide adequate information for evaluation purposes. 2% of the time we will be wrong - we have to determine if this false negatives is acceptable risk to industry.\n",
    "\n",
    "Another, more important reason why attempting to learn from an imbalanced dataset is difficult is that many algorithms assume balanced class distributions or relatively equal costs of misclassification. If that is not the case, then important distinguishing characteristics may go unlearned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOT using SFrame\n",
    "\n",
    "Download the list of indices for the training and validation sets: module-8-assignment-1-train-idx.json, module-8-assignment-1-validation-idx.json. Then follow the following steps:\n",
    "\n",
    "*    Apply one-hot encoding to loans. Your tool may have a function for one-hot encoding. Alternatively, see #7 for implementation hints.\n",
    "*    Load the JSON files into the lists train_idx and validation_idx.\n",
    "*    Perform train/validation split using train_idx and validation_idx. In Pandas, for instance:\n",
    "\n",
    "train_data = loans.iloc[train_idx]\n",
    "\n",
    "validation_data = loans.iloc[validation_idx]\n",
    "\n",
    "Note. Some elements in loans are included neither in train_data nor validation_data. This is to perform sampling to achieve class balance.\n",
    "\n",
    "Now proceed to the section \"Gradient boosted tree classifier\", skipping three sections below, (1) handling class imbalance and (2) one hot encoding and (3) split train test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding\n",
    "\n",
    "For scikit-learn's decision tree implementation, it numerical values for it's data matrix. This means you will have to turn categorical variables into binary features via one-hot encoding.\n",
    "\n",
    "**7.** We've seen this same piece of code in earlier assignments. Again, feel free to use this piece of code as is. Refer to the API documentation for a deeper understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncategorical_variables = []\\nfor feat_name, feat_type in zip(loans_data.column_names(), loans_data.column_types()):\\n    if feat_type == str:\\n        categorical_variables.append(feat_name)\\n\\nfor feature in categorical_variables:\\n    loans_data_one_hot_encoded = loans_data[feature].apply(lambda x: {x: 1})\\n    loans_data_unpacked = loans_data_one_hot_encoded.unpack(column_name_prefix=feature)\\n\\n    # Change None's to 0's\\n    for column in loans_data_unpacked.column_names():\\n        loans_data_unpacked[column] = loans_data_unpacked[column].fillna(0)\\n\\n    loans_data.remove_column(feature)\\n    loans_data.add_columns(loans_data_unpacked)\\n\\nloans_data.column_names()\\n\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "categorical_variables = []\n",
    "for feat_name, feat_type in zip(loans_data.column_names(), loans_data.column_types()):\n",
    "    if feat_type == str:\n",
    "        categorical_variables.append(feat_name)\n",
    "\n",
    "for feature in categorical_variables:\n",
    "    loans_data_one_hot_encoded = loans_data[feature].apply(lambda x: {x: 1})\n",
    "    loans_data_unpacked = loans_data_one_hot_encoded.unpack(column_name_prefix=feature)\n",
    "\n",
    "    # Change None's to 0's\n",
    "    for column in loans_data_unpacked.column_names():\n",
    "        loans_data_unpacked[column] = loans_data_unpacked[column].fillna(0)\n",
    "\n",
    "    loans_data.remove_column(feature)\n",
    "    loans_data.add_columns(loans_data_unpacked)\n",
    "\n",
    "loans_data.column_names()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** We split the data into training data and validation data. We used `seed=1` to make sure everyone gets the same results. We will use the validation data to help us select model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set   : 37219 data points\n",
      "Validation set       : 9284 data points\n"
     ]
    }
   ],
   "source": [
    "train_data, validation_data = loans_data.random_split(.8, seed=1)\n",
    "print 'Training set   : %d data points' % len(train_data)\n",
    "print 'Validation set       : %d data points' % len(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">safe_loans</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">grade</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sub_grade_num</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">short_emp</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">emp_length_num</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">home_ownership</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">dti</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">purpose</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">payment_inc_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">C</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RENT</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">car</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.3932</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">delinq_2yrs</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">delinq_2yrs_zero</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">inq_last_6mths</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">last_delinq_none</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">last_major_derog_none</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">open_acc</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">pub_rec</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">pub_rec_zero</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">revol_util</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">total_rec_late_fee</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">int_rate</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">total_rec_int</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">annual_inc</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">funded_amnt</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">funded_amnt_inv</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">installment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9.4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15.27</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">435.17</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">30000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2500</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2500</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">59.83</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[1 rows x 25 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tsafe_loans\tint\n",
       "\tgrade\tstr\n",
       "\tsub_grade_num\tfloat\n",
       "\tshort_emp\tint\n",
       "\temp_length_num\tint\n",
       "\thome_ownership\tstr\n",
       "\tdti\tfloat\n",
       "\tpurpose\tstr\n",
       "\tpayment_inc_ratio\tfloat\n",
       "\tdelinq_2yrs\tint\n",
       "\tdelinq_2yrs_zero\tint\n",
       "\tinq_last_6mths\tint\n",
       "\tlast_delinq_none\tint\n",
       "\tlast_major_derog_none\tint\n",
       "\topen_acc\tint\n",
       "\tpub_rec\tint\n",
       "\tpub_rec_zero\tint\n",
       "\trevol_util\tfloat\n",
       "\ttotal_rec_late_fee\tfloat\n",
       "\tint_rate\tfloat\n",
       "\ttotal_rec_int\tfloat\n",
       "\tannual_inc\tint\n",
       "\tfunded_amnt\tint\n",
       "\tfunded_amnt_inv\tint\n",
       "\tinstallment\tfloat\n",
       "\n",
       "Rows: 1\n",
       "\n",
       "Data:\n",
       "+------------+-------+---------------+-----------+----------------+----------------+\n",
       "| safe_loans | grade | sub_grade_num | short_emp | emp_length_num | home_ownership |\n",
       "+------------+-------+---------------+-----------+----------------+----------------+\n",
       "|     -1     |   C   |      0.8      |     1     |       1        |      RENT      |\n",
       "+------------+-------+---------------+-----------+----------------+----------------+\n",
       "+-----+---------+-------------------+-------------+------------------+----------------+\n",
       "| dti | purpose | payment_inc_ratio | delinq_2yrs | delinq_2yrs_zero | inq_last_6mths |\n",
       "+-----+---------+-------------------+-------------+------------------+----------------+\n",
       "| 1.0 |   car   |       2.3932      |      0      |        1         |       5        |\n",
       "+-----+---------+-------------------+-------------+------------------+----------------+\n",
       "+------------------+-----------------------+----------+---------+--------------+\n",
       "| last_delinq_none | last_major_derog_none | open_acc | pub_rec | pub_rec_zero |\n",
       "+------------------+-----------------------+----------+---------+--------------+\n",
       "|        1         |           1           |    3     |    0    |      1       |\n",
       "+------------------+-----------------------+----------+---------+--------------+\n",
       "+------------+--------------------+----------+-----+\n",
       "| revol_util | total_rec_late_fee | int_rate | ... |\n",
       "+------------+--------------------+----------+-----+\n",
       "|    9.4     |        0.0         |  15.27   | ... |\n",
       "+------------+--------------------+----------+-----+\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">safe_loans</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">grade</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sub_grade_num</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">short_emp</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">emp_length_num</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">home_ownership</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">dti</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">purpose</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">payment_inc_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">D</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RENT</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">13.97</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">other</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.96736</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">delinq_2yrs</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">delinq_2yrs_zero</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">inq_last_6mths</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">last_delinq_none</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">last_major_derog_none</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">open_acc</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">pub_rec</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">pub_rec_zero</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">14</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">revol_util</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">total_rec_late_fee</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">int_rate</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">total_rec_int</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">annual_inc</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">funded_amnt</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">funded_amnt_inv</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">installment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">59.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">16.77</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">719.11</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">50004</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">123.65</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[1 rows x 25 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tsafe_loans\tint\n",
       "\tgrade\tstr\n",
       "\tsub_grade_num\tfloat\n",
       "\tshort_emp\tint\n",
       "\temp_length_num\tint\n",
       "\thome_ownership\tstr\n",
       "\tdti\tfloat\n",
       "\tpurpose\tstr\n",
       "\tpayment_inc_ratio\tfloat\n",
       "\tdelinq_2yrs\tint\n",
       "\tdelinq_2yrs_zero\tint\n",
       "\tinq_last_6mths\tint\n",
       "\tlast_delinq_none\tint\n",
       "\tlast_major_derog_none\tint\n",
       "\topen_acc\tint\n",
       "\tpub_rec\tint\n",
       "\tpub_rec_zero\tint\n",
       "\trevol_util\tfloat\n",
       "\ttotal_rec_late_fee\tfloat\n",
       "\tint_rate\tfloat\n",
       "\ttotal_rec_int\tfloat\n",
       "\tannual_inc\tint\n",
       "\tfunded_amnt\tint\n",
       "\tfunded_amnt_inv\tint\n",
       "\tinstallment\tfloat\n",
       "\n",
       "Rows: 1\n",
       "\n",
       "Data:\n",
       "+------------+-------+---------------+-----------+----------------+----------------+\n",
       "| safe_loans | grade | sub_grade_num | short_emp | emp_length_num | home_ownership |\n",
       "+------------+-------+---------------+-----------+----------------+----------------+\n",
       "|     -1     |   D   |      0.4      |     0     |       3        |      RENT      |\n",
       "+------------+-------+---------------+-----------+----------------+----------------+\n",
       "+-------+---------+-------------------+-------------+------------------+----------------+\n",
       "|  dti  | purpose | payment_inc_ratio | delinq_2yrs | delinq_2yrs_zero | inq_last_6mths |\n",
       "+-------+---------+-------------------+-------------+------------------+----------------+\n",
       "| 13.97 |  other  |      2.96736      |      3      |        0         |       0        |\n",
       "+-------+---------+-------------------+-------------+------------------+----------------+\n",
       "+------------------+-----------------------+----------+---------+--------------+\n",
       "| last_delinq_none | last_major_derog_none | open_acc | pub_rec | pub_rec_zero |\n",
       "+------------------+-----------------------+----------+---------+--------------+\n",
       "|        0         |           1           |    14    |    0    |      1       |\n",
       "+------------------+-----------------------+----------+---------+--------------+\n",
       "+------------+--------------------+----------+-----+\n",
       "| revol_util | total_rec_late_fee | int_rate | ... |\n",
       "+------------+--------------------+----------+-----+\n",
       "|    59.5    |        0.0         |  16.77   | ... |\n",
       "+------------+--------------------+----------+-----+\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosted tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9.** Gradient boosted trees are a powerful variant of boosting methods; they have been used to win many [Kaggle](https://www.kaggle.com/) competitions, and have been widely used in industry.  We will explore the predictive power of multiple decision trees as opposed to a single decision tree.\n",
    "\n",
    "**Additional reading:** If you are interested in gradient boosted trees, here is some additional reading material:\n",
    "* [GraphLab Create user guide](https://dato.com/learn/userguide/supervised-learning/boosted_trees_classifier.html)\n",
    "* [Advanced material on boosted trees](http://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf)\n",
    "\n",
    "\n",
    "We will now train models to predict `safe_loans` using the features above. In this section, we will experiment with training an ensemble of 5 trees. To cap the ensemble classifier at 5 trees, we call the function with **max_iterations=5** (recall that each iterations corresponds to adding a tree). We set `validation_set=None` to make sure everyone gets the same results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also use the built-in scikit learn gradient boosting classifier ([sklearn.ensemble.GradientBoostingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)) to create a gradient boosted classifier on the training data. You will need to import sklearn, sklearn.ensemble, and numpy.\n",
    "\n",
    "You will have to first convert the SFrame into a numpy data matrix. See the [API](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for more information. You will also have to extract the label column. Make sure to set max_depth=6 and n_estimators=5.\n",
    "\n",
    "see also [vidhya](https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/) for how to tune learning parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Boosted trees classifier:</pre>"
      ],
      "text/plain": [
       "Boosted trees classifier:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 37219</pre>"
      ],
      "text/plain": [
       "Number of examples          : 37219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 24</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 24</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+-------------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+-------------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Elapsed Time | Training-accuracy | Training-log_loss |</pre>"
      ],
      "text/plain": [
       "| Iteration | Elapsed Time | Training-accuracy | Training-log_loss |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+-------------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+-------------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 0.036882     | 0.657541          | 0.657139          |</pre>"
      ],
      "text/plain": [
       "| 1         | 0.036882     | 0.657541          | 0.657139          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 0.068983     | 0.656976          | 0.636157          |</pre>"
      ],
      "text/plain": [
       "| 2         | 0.068983     | 0.656976          | 0.636157          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 0.100961     | 0.664983          | 0.623206          |</pre>"
      ],
      "text/plain": [
       "| 3         | 0.100961     | 0.664983          | 0.623206          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 0.139024     | 0.668476          | 0.613783          |</pre>"
      ],
      "text/plain": [
       "| 4         | 0.139024     | 0.668476          | 0.613783          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 0.174465     | 0.673339          | 0.606229          |</pre>"
      ],
      "text/plain": [
       "| 5         | 0.174465     | 0.673339          | 0.606229          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+-------------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+-------------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_5 = graphlab.boosted_trees_classifier.create(train_data, validation_set=None, \n",
    "        target = target, features = features, max_iterations = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions\n",
    "\n",
    "**10.** Just like we did in previous sections, let us consider a few positive and negative examples **from the validation set**. We will do the following:\n",
    "* Predict whether or not a loan is likely to default.\n",
    "* Predict the probability with which the loan is likely to default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">safe_loans</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">grade</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sub_grade_num</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">short_emp</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">emp_length_num</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">home_ownership</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">dti</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">purpose</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">B</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MORTGAGE</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">29.44</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">credit_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">B</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RENT</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">12.19</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">credit_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">D</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">RENT</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">13.97</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">A</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">11</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">MORTGAGE</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">16.33</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">debt_consolidation</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">payment_inc_ratio</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">delinq_2yrs</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">delinq_2yrs_zero</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">inq_last_6mths</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">last_delinq_none</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">last_major_derog_none</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">open_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6.30496</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">13.4952</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.96736</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.90524</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">17</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">pub_rec</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">pub_rec_zero</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">revol_util</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">total_rec_late_fee</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">int_rate</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">total_rec_int</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">annual_inc</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">funded_amnt</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">funded_amnt_inv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">93.9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9.91</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">823.48</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">92000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">59.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">11.71</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1622.21</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">25000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8500</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">59.5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">16.77</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">719.11</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">50004</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">62.1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">696.99</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">100000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5000</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5000</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">installment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">483.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">281.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">123.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">158.77</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[4 rows x 25 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tsafe_loans\tint\n",
       "\tgrade\tstr\n",
       "\tsub_grade_num\tfloat\n",
       "\tshort_emp\tint\n",
       "\temp_length_num\tint\n",
       "\thome_ownership\tstr\n",
       "\tdti\tfloat\n",
       "\tpurpose\tstr\n",
       "\tpayment_inc_ratio\tfloat\n",
       "\tdelinq_2yrs\tint\n",
       "\tdelinq_2yrs_zero\tint\n",
       "\tinq_last_6mths\tint\n",
       "\tlast_delinq_none\tint\n",
       "\tlast_major_derog_none\tint\n",
       "\topen_acc\tint\n",
       "\tpub_rec\tint\n",
       "\tpub_rec_zero\tint\n",
       "\trevol_util\tfloat\n",
       "\ttotal_rec_late_fee\tfloat\n",
       "\tint_rate\tfloat\n",
       "\ttotal_rec_int\tfloat\n",
       "\tannual_inc\tint\n",
       "\tfunded_amnt\tint\n",
       "\tfunded_amnt_inv\tint\n",
       "\tinstallment\tfloat\n",
       "\n",
       "Rows: 4\n",
       "\n",
       "Data:\n",
       "+------------+-------+---------------+-----------+----------------+----------------+\n",
       "| safe_loans | grade | sub_grade_num | short_emp | emp_length_num | home_ownership |\n",
       "+------------+-------+---------------+-----------+----------------+----------------+\n",
       "|     1      |   B   |      0.2      |     0     |       3        |    MORTGAGE    |\n",
       "|     1      |   B   |      0.6      |     1     |       1        |      RENT      |\n",
       "|     -1     |   D   |      0.4      |     0     |       3        |      RENT      |\n",
       "|     -1     |   A   |      1.0      |     0     |       11       |    MORTGAGE    |\n",
       "+------------+-------+---------------+-----------+----------------+----------------+\n",
       "+-------+--------------------+-------------------+-------------+------------------+\n",
       "|  dti  |      purpose       | payment_inc_ratio | delinq_2yrs | delinq_2yrs_zero |\n",
       "+-------+--------------------+-------------------+-------------+------------------+\n",
       "| 29.44 |    credit_card     |      6.30496      |      0      |        1         |\n",
       "| 12.19 |    credit_card     |      13.4952      |      0      |        1         |\n",
       "| 13.97 |       other        |      2.96736      |      3      |        0         |\n",
       "| 16.33 | debt_consolidation |      1.90524      |      0      |        1         |\n",
       "+-------+--------------------+-------------------+-------------+------------------+\n",
       "+----------------+------------------+-----------------------+----------+---------+\n",
       "| inq_last_6mths | last_delinq_none | last_major_derog_none | open_acc | pub_rec |\n",
       "+----------------+------------------+-----------------------+----------+---------+\n",
       "|       0        |        1         |           1           |    8     |    0    |\n",
       "|       0        |        1         |           1           |    8     |    0    |\n",
       "|       0        |        0         |           1           |    14    |    0    |\n",
       "|       0        |        1         |           1           |    17    |    0    |\n",
       "+----------------+------------------+-----------------------+----------+---------+\n",
       "+--------------+------------+--------------------+----------+-----+\n",
       "| pub_rec_zero | revol_util | total_rec_late_fee | int_rate | ... |\n",
       "+--------------+------------+--------------------+----------+-----+\n",
       "|      1       |    93.9    |        0.0         |   9.91   | ... |\n",
       "|      1       |    59.1    |        0.0         |  11.71   | ... |\n",
       "|      1       |    59.5    |        0.0         |  16.77   | ... |\n",
       "|      1       |    62.1    |        0.0         |   8.9    | ... |\n",
       "+--------------+------------+--------------------+----------+-----+\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all positive and negative examples.\n",
    "validation_safe_loans = validation_data[validation_data[target] == 1]\n",
    "validation_risky_loans = validation_data[validation_data[target] == -1]\n",
    "\n",
    "# Select 2 examples from the validation set for positive & negative loans\n",
    "sample_validation_data_risky = validation_risky_loans[0:2]\n",
    "sample_validation_data_safe = validation_safe_loans[0:2]\n",
    "\n",
    "# Append the 4 examples into a single dataset\n",
    "sample_validation_data = sample_validation_data_safe.append(sample_validation_data_risky)\n",
    "sample_validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on sample validation data\n",
    "\n",
    "**11.** For each row in the **sample_validation_data**, write code to make **model_5** predict whether or not the loan is classified as a **safe loan**.\n",
    "\n",
    "**Hint:** Use the `predict` method in `model_5` for this. If you are using scikit-learn, you can use the [.predict()](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier.predict) method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, -1, 1]\n",
      "[1, 1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "predictions = model_5.predict(sample_validation_data)\n",
    "print predictions\n",
    "print sample_validation_data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of predictions +ve class:3\n",
      "num of predictions -ve class:1\n",
      "-----------------------------------------------------\n",
      "# Reviews   correctly classified = 3\n",
      "# Reviews incorrectly classified = 1\n",
      "# Reviews total                  = 4\n",
      "-----------------------------------------------------\n",
      "Accuracy = 0.75\n"
     ]
    }
   ],
   "source": [
    "print \"num of predictions +ve class:%d\" %(predictions == +1).sum()\n",
    "print \"num of predictions -ve class:%d\" %(predictions == -1).sum()\n",
    "actuals = sample_validation_data[target]\n",
    "num_correct = sum( np.equal(predictions, actuals))\n",
    "num_mistakes = len(sample_validation_data) - num_correct\n",
    "accuracy = 1. * num_correct/len(sample_validation_data)\n",
    "print \"-----------------------------------------------------\"\n",
    "print '# Reviews   correctly classified =', num_correct\n",
    "print '# Reviews incorrectly classified =', num_mistakes\n",
    "print '# Reviews total                  =', len(sample_validation_data)\n",
    "print \"-----------------------------------------------------\"\n",
    "print 'Accuracy = %.2f' % accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question:** What percentage of the predictions on `sample_validation_data` did `model_5` get correct?\n",
    "\n",
    "### Prediction probabilities\n",
    "\n",
    "**12.** For each row in the **sample_validation_data**, what is the probability (according **model_5**) of a loan being classified as **safe**? \n",
    "\n",
    "**Hint:** Set `output_type='probability'` to make **probability** predictions using `model_5` on `sample_validation_data`: If you are using scikit-learn, you can use the [.predict_proba()](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier.predict_proba) method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob predictions [0.7045905590057373, 0.5963408946990967, 0.44925159215927124, 0.6119099855422974]\n",
      "\n",
      "Prob 2 class [1, 1, -1, 1]\n",
      "\n",
      "Actual class labels\n",
      "[1, 1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "prob_predictions = model_5.predict(sample_validation_data,output_type='probability')\n",
    "#print \"%0.2f\" %(predictions)\n",
    "print \"Prob predictions\", prob_predictions\n",
    "\n",
    "#print [+1 if x >= 0.5 else -1 for x in enumerate(prob_predictions[:,1])]\n",
    "prob_2_class = [+1 if x >= 0.5 else -1 for x in prob_predictions]  \n",
    "print \"\\nProb 2 class\",prob_2_class\n",
    "\n",
    "print \"\\nActual class labels\\n\", sample_validation_data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** According to **model_5**, which loan is the least likely to be a safe loan?\n",
    "\n",
    "**Checkpoint:** Can you verify that for all the predictions with `probability >= 0.5`, the model predicted the label **+1**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest probabilty of loan being safe = 0.4493 for item at index 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'annual_inc': 50004,\n",
       " 'delinq_2yrs': 3,\n",
       " 'delinq_2yrs_zero': 0,\n",
       " 'dti': 13.97,\n",
       " 'emp_length_num': 3,\n",
       " 'funded_amnt': 5000,\n",
       " 'funded_amnt_inv': 5000,\n",
       " 'grade': 'D',\n",
       " 'home_ownership': 'RENT',\n",
       " 'inq_last_6mths': 0,\n",
       " 'installment': 123.65,\n",
       " 'int_rate': 16.77,\n",
       " 'last_delinq_none': 0,\n",
       " 'last_major_derog_none': 1,\n",
       " 'open_acc': 14,\n",
       " 'payment_inc_ratio': 2.96736,\n",
       " 'pub_rec': 0,\n",
       " 'pub_rec_zero': 1,\n",
       " 'purpose': 'other',\n",
       " 'revol_util': 59.5,\n",
       " 'safe_loans': -1,\n",
       " 'short_emp': 0,\n",
       " 'sub_grade_num': 0.4,\n",
       " 'total_rec_int': 719.11,\n",
       " 'total_rec_late_fee': 0.0}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_prob, index = min([(v,i) for i,v in enumerate(prob_predictions)])\n",
    "print \"Lowest probabilty of loan being safe = %0.4f for item at index %d\" %(min_prob, index)\n",
    "\n",
    "sample_validation_data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number matching  4\n"
     ]
    }
   ],
   "source": [
    "prob_2_class = [+1 if x >= 0.5 else -1 for x in prob_predictions]  \n",
    "print \"Number matching \", sum( np.equal(predictions, prob_2_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluating the model on the validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the accuracy is defined as follows:\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "**13.** Evaluate the accuracy of the **model_5** on the **validation_data**.\n",
    "\n",
    "**Hint**: Use the `.evaluate()` method in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.66813873330461,\n",
       " 'auc': 0.7247215702188436,\n",
       " 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      -1      |        1        |  1618 |\n",
       " |      1       |        -1       |  1463 |\n",
       " |      -1      |        -1       |  3054 |\n",
       " |      1       |        1        |  3149 |\n",
       " +--------------+-----------------+-------+\n",
       " [4 rows x 3 columns],\n",
       " 'f1_score': 0.6715001599317625,\n",
       " 'log_loss': 0.6176131769648966,\n",
       " 'precision': 0.6605831760016782,\n",
       " 'recall': 0.6827840416305291,\n",
       " 'roc_curve': Columns:\n",
       " \tthreshold\tfloat\n",
       " \tfpr\tfloat\n",
       " \ttpr\tfloat\n",
       " \tp\tint\n",
       " \tn\tint\n",
       " \n",
       " Rows: 100001\n",
       " \n",
       " Data:\n",
       " +-----------+-----+-----+------+------+\n",
       " | threshold | fpr | tpr |  p   |  n   |\n",
       " +-----------+-----+-----+------+------+\n",
       " |    0.0    | 1.0 | 1.0 | 4612 | 4672 |\n",
       " |   1e-05   | 1.0 | 1.0 | 4612 | 4672 |\n",
       " |   2e-05   | 1.0 | 1.0 | 4612 | 4672 |\n",
       " |   3e-05   | 1.0 | 1.0 | 4612 | 4672 |\n",
       " |   4e-05   | 1.0 | 1.0 | 4612 | 4672 |\n",
       " |   5e-05   | 1.0 | 1.0 | 4612 | 4672 |\n",
       " |   6e-05   | 1.0 | 1.0 | 4612 | 4672 |\n",
       " |   7e-05   | 1.0 | 1.0 | 4612 | 4672 |\n",
       " |   8e-05   | 1.0 | 1.0 | 4612 | 4672 |\n",
       " |   9e-05   | 1.0 | 1.0 | 4612 | 4672 |\n",
       " +-----------+-----+-----+------+------+\n",
       " [100001 rows x 5 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.evaluate(validation_data)\n",
    "#print round( model_5.evaluate(validation_data), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66813873330461"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.evaluate(validation_data)['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14.** Calculate the number of **false positives** made by the model. False positives: Loans that were actually risky but were predicted to be safe. These are much more expensive because it results in a risky loan being given. False positives are predictions where the model predicts +1 but the true label is -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model_5.predict(validation_data)\n",
    "true_labels = validation_data['safe_loans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1618"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.sum([p == +1 and t == -1, for p in predictions, t in true_labels])\n",
    "# sum([p == +1 for p in predictions]) and sum([ t == -1 for t in true_labels])   <-- give 4672!\n",
    "false_positives = sum((predictions == +1) & (true_labels == -1))\n",
    "false_positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question**: What is the number of **false positives** on the **validation_data**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15.** Calculate the number of **false negatives** made by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1463"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives = sum((predictions == -1) & (true_labels == +1))\n",
    "false_negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with decision trees\n",
    "\n",
    "In the earlier assignment, we saw that the prediction accuracy of the decision trees was around **0.64** (rounded). In this assignment, we saw that **model_5** has an accuracy of **0.67** (rounded).\n",
    "\n",
    "Here, we quantify the benefit of the extra 3% increase in accuracy of **model_5** in comparison with a single decision tree from the original decision tree assignment.\n",
    "\n",
    "As we explored in the earlier assignment, we calculated the cost of the mistakes made by the model. We again consider the same costs as follows:\n",
    "\n",
    "* **False negatives**: Assume a cost of \\$10,000 per false negative.\n",
    "* **False positives**: Assume a cost of \\$20,000 per false positive.\n",
    "\n",
    "Assume that the number of false positives and false negatives for the learned decision tree was\n",
    "\n",
    "* **False negatives**: 1936\n",
    "* **False positives**: 1503\n",
    "\n",
    "Using the costs defined above and the number of false positives and false negatives for the decision tree, we can calculate the total cost of the mistakes made by the decision tree model as follows:\n",
    "\n",
    "```\n",
    "cost = $10,000 * 1936  + $20,000 * 1503 = $49,420,000\n",
    "```\n",
    "\n",
    "The total cost of the mistakes of the model is $49.42M. That is a **lot of money**!.\n",
    "\n",
    "**16.** Calculate the cost of mistakes made by model_5 on the validation_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_cost for wrong predictions: $46990000.00\n"
     ]
    }
   ],
   "source": [
    "total_cost = 10000 * false_negatives + 20000 * false_positives\n",
    "print \"Total_cost for wrong predictions: $%.2f\" %total_cost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Using the same costs of the false positives and false negatives, what is the cost of the mistakes made by the boosted tree model (**model_5**) as evaluated on the **validation_set**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder**: Compare the cost of the mistakes made by the boosted trees model with the decision tree model. The extra 3% improvement in prediction accuracy can translate to several million dollars!  And, it was so easy to get by simply boosting our decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most positive & negative loans.\n",
    "\n",
    "In this section, we will find the loans that are most likely to be predicted **safe**. We can do this in a few steps:\n",
    "\n",
    "* **Step 1**: Use the **model_5** (the model with 5 trees) and make **probability predictions** for all the loans in the **validation_data**.\n",
    "* **Step 2**: Similar to what we did in the very first assignment, add the probability predictions as a column called **predictions** into the validation_data.\n",
    "* **Step 3**: Sort the data (in descreasing order) by the probability predictions.\n",
    "\n",
    "**17.** Start here with **Step 1** & **Step 2**. Make predictions using **model_5** for examples in the **validation_data**. Use `output_type = probability`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: float\n",
       "Rows: 4\n",
       "[0.44925159215927124, 0.6119099855422974, 0.38359811902046204, 0.3693307042121887]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data['predictions'] = model_5.predict(validation_data,output_type='probability')\n",
    "validation_data.sort('predictions', ascending = False)\n",
    "validation_data['predictions'].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** For each row, the probabilities should be a number in the range **[0, 1]**. We have provided a simple check here to make sure your answers are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your loans      : [0.44925159215927124, 0.6119099855422974, 0.38359811902046204, 0.3693307042121887]\n",
      "\n",
      "Expected answer : [0.4492515948736132, 0.6119100103640573, 0.3835981314851436, 0.3693306705994325]\n"
     ]
    }
   ],
   "source": [
    "print \"Your loans      : %s\\n\" % validation_data['predictions'].head(4)\n",
    "print \"Expected answer : %s\" % [0.4492515948736132, 0.6119100103640573,\n",
    "                                0.3835981314851436, 0.3693306705994325]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**18.** Now, we are ready to go to **Step 3**. You can now use the `prediction` column to sort the loans in **validation_data** (in descending order) by prediction probability. Find the top 5 loans with the highest probability of being predicted as a **safe loan**.\n",
    "\n",
    "graphlab.SFrame.topk\n",
    "\n",
    "reverse : bool, optional, If True, return the top k rows in ascending order, otherwise, in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: str\n",
       "Rows: 5\n",
       "['A', 'A', 'A', 'A', 'A']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data['predictions'] = model_5.predict(validation_data,output_type='probability')\n",
    "validation_data.topk('predictions', k=5, reverse=False)\n",
    "validation_data.sort('predictions', ascending=False)['grade'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz question**: What grades are the top 5 loans?\n",
    "\n",
    "**19.** Let us repeat this excercise to find the top 5 loans (in the **validation_data**) with the **lowest probability** of being predicted as a **safe loan**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: str\n",
       "Rows: 5\n",
       "['C', 'B', 'D', 'C', 'C']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.topk('predictions', k=5, reverse=True)\n",
    "validation_data.sort('predictions', ascending=False)['grade'].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** You should expect to see 5 loans with the grade ['**D**', '**C**', '**C**', '**C**', '**B**']."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of adding more trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20.** In this assignment, we will train 5 different ensemble classifiers in the form of gradient boosted trees. We will train models with 10, 50, 100, 200, and 500 trees.  We use the **max_iterations** parameter in the boosted tree module. \n",
    "\n",
    "If using skit-learn, use the **n_estimators** parameter to control the number of trees. Remember to keep **max_depth = 6**.\n",
    "Let's get sarted with a model with **max_iterations = 10**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train 5 models with **max_iterations** to be:\n",
    "* `max_iterations = 10`, \n",
    "* `max_iterations = 50`, \n",
    "* `max_iterations = 100`\n",
    "* `max_iterations = 200`\n",
    "* `max_iterations = 500`. \n",
    "\n",
    "Let us call these models **model_10**,**model_50**, **model_100**, **model_200**, and **model_500**. You can pass in `verbose=False` in order to suppress the printed output.\n",
    "\n",
    "**Warning:** This could take a couple of minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_10 = graphlab.boosted_trees_classifier.create(train_data, validation_set=None, \n",
    "        target = target, features = features, max_iterations = 10, verbose=False)\n",
    "model_50 = graphlab.boosted_trees_classifier.create(train_data, validation_set=None, \n",
    "        target = target, features = features, max_iterations = 50, verbose=False)\n",
    "model_100 = graphlab.boosted_trees_classifier.create(train_data, validation_set=None, \n",
    "        target = target, features = features, max_iterations = 100, verbose=False)\n",
    "model_200 = graphlab.boosted_trees_classifier.create(train_data, validation_set=None, \n",
    "        target = target, features = features, max_iterations = 200, verbose=False)\n",
    "model_500 = graphlab.boosted_trees_classifier.create(train_data, validation_set=None, \n",
    "        target = target, features = features, max_iterations = 500, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare accuracy on entire validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**21.** Now we will compare the predicitve accuracy of our models on the validation set. Evaluate the **accuracy** of the 10, 50, 100, 200, and 500 tree models on the **validation_data**. Use the `.evaluate` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data, classification error (model 10  : 0.672770357604\n",
      "Validation data, classification error (model 50  : 0.690758293839\n",
      "Validation data, classification error (model 100 : 0.691727703576\n",
      "Validation data, classification error (model 200 : 0.684510986644\n",
      "Validation data, classification error (model 500 : 0.671800947867\n"
     ]
    }
   ],
   "source": [
    "print \"Validation data, classification error (model 10  :\", \\\n",
    "model_10.evaluate(validation_data)['accuracy']\n",
    "print \"Validation data, classification error (model 50  :\", \\\n",
    "model_50.evaluate(validation_data)['accuracy']\n",
    "print \"Validation data, classification error (model 100 :\", \\\n",
    "model_100.evaluate(validation_data)['accuracy']\n",
    "print \"Validation data, classification error (model 200 :\", \\\n",
    "model_200.evaluate(validation_data)['accuracy']\n",
    "print \"Validation data, classification error (model 500 :\", \\\n",
    "model_500.evaluate(validation_data)['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question:** Which model has the **best** accuracy on the **validation_data**? model_100 - highest accuracy.\n",
    "**Quiz Question:** Is it always true that the model with the most trees will perform best on test data? No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the training and validation error vs. number of trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from the lecture that the classification error is defined as\n",
    "\n",
    "$$\n",
    "\\mbox{classification error} = 1 - \\mbox{accuracy} \n",
    "$$\n",
    "\n",
    "In this section, we will plot the **training and validation errors versus the number of trees** to get a sense of how these models are performing. We will compare the 10, 50, 100, 200, and 500 tree models. You will need [matplotlib](http://matplotlib.org/downloads.html) in order to visualize the plots. \n",
    "\n",
    "**22.** First, define a function to make the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def make_figure(dim, title, xlabel, ylabel, legend):\n",
    "    plt.rcParams['figure.figsize'] = dim\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if legend is not None:\n",
    "        plt.legend(loc=legend, prop={'size':15})\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to plot the classification errors (on the **train_data** and **validation_data**) versus the number of trees, we will need lists of these accuracies, which we get by applying the method `.evaluate`. \n",
    "\n",
    "**Steps to follow:**\n",
    "\n",
    "* **Step 1:** Calculate the classification error for model on the training data (**train_data**).\n",
    "* **Step 2:** Store the training errors into a list (called `training_errors`) that looks like this:\n",
    "```\n",
    "[train_err_10, train_err_50, ..., train_err_500]\n",
    "```\n",
    "* **Step 3:** Calculate the classification error of each model on the validation data (**validation_data**).\n",
    "* **Step 4:** Store the validation classification error into a list (called `validation_errors`) that looks like this:\n",
    "```\n",
    "[validation_err_10, validation_err_50, ..., validation_err_500]\n",
    "```\n",
    "Once that has been completed, the rest of the code should be able to evaluate correctly and generate the plot.\n",
    "\n",
    "\n",
    "**23.** Let us start with **Step 1**. Write code to compute the classification error on the **train_data** for models **model_10**, **model_50**, **model_100**, **model_200**, and **model_500**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31, 0.25, 0.2, 0.14, 0.04]\n"
     ]
    }
   ],
   "source": [
    "training_accuracy = [model_10.evaluate(train_data)['accuracy'], \\\n",
    "                   model_50.evaluate(train_data)['accuracy'],  model_100.evaluate(train_data)['accuracy'], \\\n",
    "                   model_200.evaluate(train_data)['accuracy'], model_500.evaluate(train_data)['accuracy']]\n",
    "\n",
    "training_errors = []\n",
    "for m in [model_10, model_50, model_100, model_200, model_500]:\n",
    "    training_errors.append(round(1 - m.evaluate(train_data)['accuracy'],2))\n",
    "print training_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**24.** Now, let us run **Step 2**. Save the training errors into a list called **training_errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31, 0.25, 0.2, 0.14, 0.04]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training_errors = [train_err_10, train_err_50, train_err_100, train_err_200, train_err_500]\n",
    "training_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**25.** Now, onto **Step 3**. Write code to compute the classification error on the **validation_data** for models **model_10**, **model_50**, **model_100**, **model_200**, and **model_500**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33, 0.31, 0.31, 0.32, 0.33]\n"
     ]
    }
   ],
   "source": [
    "validation_accuracy = [model_10.evaluate(validation_data)['accuracy'], \\\n",
    "                     model_50.evaluate(validation_data)['accuracy'], model_100.evaluate(validation_data)['accuracy'], \\\n",
    "                     model_200.evaluate(validation_data)['accuracy'], model_500.evaluate(validation_data)['accuracy'] ]\n",
    "\n",
    "\n",
    "\n",
    "validation_errors = []\n",
    "for m in [model_10, model_50, model_100, model_200, model_500]:\n",
    "    validation_errors.append(round(1 - m.evaluate(validation_data)['accuracy'],2))\n",
    "print validation_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**26.** Now, let us run **Step 4**. Save the training errors into a list called **validation_errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.33, 0.31, 0.31, 0.32, 0.33]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation_errors = [validation_err_10, validation_err_50, validation_err_100, validation_err_200, validation_err_500]\n",
    "validation_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**27.** Now, we will plot the **training_errors** and **validation_errors** versus the number of trees. We will compare the 10, 50, 100, 200, and 500 tree models. We provide some plotting code to visualize the plots within this notebook. \n",
    "\n",
    "**28.** Run the following code to visualize the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAroAAAFSCAYAAAAdAnxrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f56d1b094d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([10, 50, 100, 200, 500], training_errors, linewidth=4.0, label='Training error')\n",
    "plt.plot([10, 50, 100, 200, 500], validation_errors, linewidth=4.0, label='Validation error')\n",
    "\n",
    "make_figure(dim=(10,5), title='Error vs number of trees',\n",
    "            xlabel='Number of trees',\n",
    "            ylabel='Classification error',\n",
    "            legend='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question**: Does the training error reduce as the number of trees increases?  Yes!\n",
    "\n",
    "**Quiz question**: Is it always true that the validation error will reduce as the number of trees increases? No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
