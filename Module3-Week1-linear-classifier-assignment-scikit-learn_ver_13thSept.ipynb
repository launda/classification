{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Course 3: Classification:  Week 1 Assignment 1\n",
    "## Predicting sentiment from product reviews\n",
    "## Pandas sklearn\n",
    "\n",
    "\n",
    "The goal of this first notebook is to explore logistic regression and feature engineering with existing GraphLab functions.\n",
    "\n",
    "In this notebook you will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative.\n",
    "\n",
    "* Use SFrames to do some feature engineering\n",
    "* Train a logistic regression model to predict the sentiment of product reviews.\n",
    "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
    "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
    "* Given the logistic regression weights, predictors and ground truth labels, write a function to compute the **accuracy** of the model.\n",
    "* Inspect the coefficients of the logistic regression model and interpret their meanings.\n",
    "* Compare multiple logistic regression models.\n",
    "\n",
    "Let's get started! see also https://github.com/smarthi/UnivOfWashington-Machine-Learning/blob/master/Classification/week1/module-2-linear-classifier-assignment-blank.ipynb\n",
    "\n",
    "see also http://logisticregressionanalysis.com/909-understanding-logistic-regression-outputpart-4-making-predictions/\n",
    "\n",
    "also http://www.ats.ucla.edu/stat/stata/webbooks/logistic/chapter1/statalog1.htm\n",
    "    \n",
    "## Fire up GraphLab Create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the latest version of GraphLab Create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation\n",
    "\n",
    "**1.** Load the dataset consisting of baby product reviews on Amazon.com. Store the data in a data frame products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183531 entries, 0 to 183530\n",
      "Data columns (total 3 columns):\n",
      "name      183213 non-null object\n",
      "review    182702 non-null object\n",
      "rating    183531 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#products = sf.SFrame('../../course-1/Week3/amazon_baby.csv')\n",
    "dtype_dict = {'name':str, 'review':str, 'rating':int}\n",
    "products = pd.read_csv('../../course-1/Week3/amazon_baby.csv', dtype = dtype_dict)\n",
    "products.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see a preview of what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features are  Index([u'name', u'review', u'rating'], dtype='object')\n",
      "Number of features = 3\n",
      "Number of data items = 550593\n",
      "2\n",
      "RangeIndex(start=0, stop=183531, step=1)\n",
      "Number of samples/rows = 183531 and num of features/cols =  3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  \\\n",
       "0  Planetwise Flannel Wipes   \n",
       "1     Planetwise Wipe Pouch   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Features are \",products.columns\n",
    "print \"Number of features = %d\" %len(products.columns)\n",
    "(num_rows,num_cols) = products.shape\n",
    "print \"Number of data items = %d\" %products.size\n",
    "print products.ndim\n",
    "print products.index\n",
    "print \"Number of samples/rows = %d and num of features/cols =  %d\" %products.shape\n",
    "products.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the word count vector for each review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explore a specific example of a baby product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name      The First Years Massaging Action Teether\n",
      "review                    A favorite in our house!\n",
      "rating                                           5\n",
      "Name: 269, dtype: object\n",
      "name      The First Years Massaging Action Teether\n",
      "review                    A favorite in our house!\n",
      "rating                                           5\n",
      "Name: 269, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>The First Years Massaging Action Teether</td>\n",
       "      <td>A favorite in our house!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name                    review  \\\n",
       "269  The First Years Massaging Action Teether  A favorite in our house!   \n",
       "\n",
       "     rating  \n",
       "269       5  "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# products.describe()\n",
    "print products.iloc[269] #iloc: Purely integer-location based indexing for selection by position\n",
    "print products.loc[269]  #loc:  Purely label based indexing for selection by label\n",
    "products[269:270]          #slicing also works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Now, we will perform 2 simple data transformations:\n",
    "\n",
    "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality, so that words \"cake.\" and \"cake!\" are counted as the same word.\n",
    "2. Apply this function to every element in the review column of products, and save the result to a new column review_clean. (Transform the reviews into word-counts. - not doing this here)\n",
    "\n",
    "**Aside**. In this notebook, we remove all punctuations for the sake of simplicity. A smarter approach to punctuations would preserve phrases such as \"I'd\", \"would've\", \"hadn't\" and so forth. See [this page](https://www.cis.upenn.edu/~treebank/tokenization.html) for an example of smart handling of punctuations.\n",
    "\n",
    "IMPORTANT. Make sure to fill n/a values in the review column with empty strings (if applicable). The n/a values indicate empty reviews. For instance, Pandas's the fillna() method lets you replace all N/A's in the review columns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation) \n",
    "\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
    "\n",
    "#review_without_puctuation = products['review'].apply(remove_punctuation)\n",
    "#products['word_count'] = sf.text_analytics.count_words(review_without_puctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print products.dtypes\n",
    "#products['review'] = products['review'].astype(str) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us explore what the sample example above looks like after these 2 transformations. Here, each entry in the **word_count** column is a dictionary where the key is the word and the value is a count of the number of times the word occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A favorite in our house!\n",
      "A favorite in our house!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "269    A favorite in our house!\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print products[269]['review']      # KeyError 269\n",
    "print products.iloc[269]['review']   # Use iloc for positional indexing\n",
    "print products.loc[269]['review']    # Use loc for label-based indexing\n",
    "\n",
    "products[269:270]['review']         #normal python slicing also works  \n",
    "#products = products.fillna({'review':''})  # fill in N/A's in the review column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract sentiments\n",
    "\n",
    "**3.** We will ignore all reviews with rating = 3, since they tend to have a neutral sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183531\n",
      "166752\n"
     ]
    }
   ],
   "source": [
    "print len(products)\n",
    "products = products[ products['rating'] != 3 ]\n",
    "print len(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Now, we will assign reviews with a rating of 4 or higher to be positive reviews, while the ones with rating of 2 or lower are negative. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label. A good way is to create an anonymous function that converts a rating into a class label and then apply that function to every element in the rating column. In SFrame, you would use apply():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "len(products) == len ( products[products['sentiment'] == -1]) + \\\n",
    "                len ( products[products['sentiment'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  name  \\\n",
       "1                Planetwise Wipe Pouch   \n",
       "2  Annas Dream Full Quilt with 2 Shams   \n",
       "\n",
       "                                              review  rating  \\\n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "\n",
       "                                        review_clean  sentiment  \n",
       "1  it came early and was not disappointed i love ...          1  \n",
       "2  Very soft and comfortable and warmer than it l...          1  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[ products['rating'] > 3].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nature\\'s Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I only purchased a second-year calendar for my...</td>\n",
       "      <td>2</td>\n",
       "      <td>I only purchased a secondyear calendar for my ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SoftPlay Giggle Jiggle Funbook, Happy Bear</td>\n",
       "      <td>This bear is absolutely adorable and I would g...</td>\n",
       "      <td>2</td>\n",
       "      <td>This bear is absolutely adorable and I would g...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "21  Nature\\'s Lullabies Second Year Sticker Calendar   \n",
       "41        SoftPlay Giggle Jiggle Funbook, Happy Bear   \n",
       "\n",
       "                                               review  rating  \\\n",
       "21  I only purchased a second-year calendar for my...       2   \n",
       "41  This bear is absolutely adorable and I would g...       2   \n",
       "\n",
       "                                         review_clean  sentiment  \n",
       "21  I only purchased a secondyear calendar for my ...         -1  \n",
       "41  This bear is absolutely adorable and I would g...         -1  "
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[ products['rating'] < 3].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see that the dataset contains an extra column called **sentiment** which is either positive (+1) or negative (-1). We can also see that all product reviews got a sentiment (+1 or -1) cause the sum of -1 and +1 sentiments add up to number of product reviews we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Let's perform a train/test split with 80% of the data in the training set and 20% of the data in the test set. We use `seed=1` so that everyone gets the same result. \n",
    "\n",
    "We are not using SFrame, so download the list of indices for the training and test sets: module-2-assignment-train-idx.json, module-2-assignment-test-idx.json. IMPORTANT: If you are using a programming language with 1-based indexing (e.g. R, Matlab), make sure to increment all indices by 1.\n",
    "\n",
    "we will need a way to pass a list of indices/integers - [see](http://pandas.pydata.org/pandas-docs/stable/indexing.html) and [this](http://www.gregreda.com/2013/10/26/working-with-pandas-dataframes)\n",
    "\n",
    "*    Use loc for label-based indexing\n",
    "*    Use iloc for positional indexing - purely integer based indexing. df.iloc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data, test_data = products.random_split(.8, seed=1)\n",
    "#print len(train_data)  #133416\n",
    "#print len(test_data)   #33336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133416\n",
      "33336\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('module2_assignment_train_idx.json', 'r') as file1: \n",
    "    train_idx = json.load(file1)   #reads entire file in one go \n",
    "\n",
    "with open('module2_assignment_test_idx.json', 'r') as file2: \n",
    "    test_idx = json.load(file2)    #reads entire file in one go \n",
    " \n",
    "train_data = products.iloc[train_idx, :]\n",
    "test_data =  products.iloc[test_idx,  :]\n",
    "print len(train_data)  #133416\n",
    "print len(test_data)   #33336"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the word count vector for each review\n",
    "\n",
    "**6.** We will now compute the word count for each word that appears in the reviews. A vector consisting of word counts is often referred to as bag-of-word features. Since most words occur in only a few reviews, word count vectors are sparse. For this reason, scikit-learn and many other tools use sparse matrices to store a collection of word count vectors. Refer to appropriate manuals to produce sparse word count vectors. General steps for extracting word count vectors are as follows:\n",
    "\n",
    "*    Learn a vocabulary (set of all words) from the training data. Only the words that show up in the training data will be considered for feature extraction.\n",
    "*    Compute the occurrences of the words in each review and collect them into a row vector.\n",
    "*    Build a sparse matrix where each row is the word count vector for the corresponding review. Call this matrix train_matrix.\n",
    "*    Using the same mapping between words and columns, convert the test data into a sparse matrix test_matrix.\n",
    "\n",
    "The following cell uses CountVectorizer in scikit-learn. Notice the token_pattern argument in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "# Use this token pattern to keep single-letter words\n",
    "\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data. \n",
    "\n",
    "Instructions for graphlab --> This model will use the column **word_count** as a feature and the column **sentiment** as the target. We will use `validation_set=None` to obtain same results as everyone else.\n",
    "\n",
    "**7.** Learn a logistic regression classifier using the training data. If you are using scikit-learn, you should create an instance of the LogisticRegression class and then call the method fit() to train the classifier. This model should use the sparse word count matrix (train_matrix) as features and the column sentiment of train_data as the target. Use the default values for other parameters. Call this model sentiment_model.\n",
    "\n",
    "**Note:** This line may take 1-2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133416, 121712)\n"
     ]
    }
   ],
   "source": [
    "print train_matrix.shape   \n",
    "# as many samples as that in train set, and 12712 columns/features!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96851951789890267"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# instantiate a logistic regression model, and fit with X and y\n",
    "# X -> sparse matrix where each row is the word count vector for the corresponding review\n",
    "model = LogisticRegression()\n",
    "X = train_matrix \n",
    "y = train_data['sentiment']\n",
    "sentiment_model = model.fit(X, y)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "sentiment_model.score(X, y)                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside**. You may get an warning to the effect of \"Terminated due to numerical difficulties --- this model may not be ideal\". It means that the quality metric (to be covered in Module 3) failed to improve in the last iteration of the run. The difficulty arises as the sentiment model puts too much weight on extremely rare words. A way to rectify this is to apply regularization, to be covered in Module 4. Regularization lessens the effect of extremely rare words. For the purpose of this assignment, however, please proceed with the model above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.** There should be over 100,000 coefficients in this sentiment_model. Recall from the lecture that positive weights w_j correspond to weights that cause positive sentiment, while negative weights correspond to negative sentiment. Calculate the number of positive (>= 0, which is actually nonnegative) coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.24016858e+00   2.97817122e-05   2.75239185e-02 ...,   1.26002631e-02\n",
      "    2.71201093e-03  -4.16780197e-05]]\n",
      "\n",
      "Non zero coefficients (including intercept) =  121713\n",
      "(sentiment_model.coef_).shape[0] 1\n",
      "sentiment_model.coef_.shape: (1, 121712)\n"
     ]
    }
   ],
   "source": [
    "print sentiment_model.coef_\n",
    "print \"\\nNon zero coefficients (including intercept) = \" , \\\n",
    "np.count_nonzero(sentiment_model.coef_) + np.count_nonzero(sentiment_model.intercept_)\n",
    "#len(model_all.sparse_coef_)\n",
    "print \"(sentiment_model.coef_).shape[0]\", (sentiment_model.coef_).shape[0]\n",
    "#print sentiment_model.coef_.getnnz()\n",
    "print \"sentiment_model.coef_.shape:\", sentiment_model.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine the coefficients - can't do sparse matrix X has no column names\n",
    "# pd.DataFrame(zip(X.columns, np.transpose(sentiment_model.coef_))).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the following block of code to calculate how many *weights* are positive ( >= 0). (**Hint**: The `'value'` column in SFrame *weights* must be positive ( >= 0))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86906\n",
      "86906\n",
      "121712\n",
      "Number of positive weights: 86906 \n",
      "Number of negative weights: 34806 \n"
     ]
    }
   ],
   "source": [
    "#build list of 1's, 1 if weight +ve, then sum the 1s'!!\n",
    "np1 = sum(1 for x in sentiment_model.coef_[0] if x > 0)    \n",
    "\n",
    "#build list - then count num of elements\n",
    "np2 = len([x for x in sentiment_model.coef_[0] if x > 0])  \n",
    "print np1\n",
    "print np2\n",
    "\n",
    "#compare this with traditional way of iterating through list, about 7 lines code...\n",
    "count_pos = 0\n",
    "count_neg = 0\n",
    "for i in range(len(sentiment_model.coef_[0])):\n",
    "    if sentiment_model.coef_[0][i] >= 0:\n",
    "        count_pos=count_pos+1\n",
    "    else:\n",
    "        count_neg=count_neg+1\n",
    "\n",
    "print count_pos + count_neg\n",
    "print \"Number of positive weights: %s \" % count_pos\n",
    "print \"Number of negative weights: %s \" % count_neg\n",
    "#print \"Total: %s \" % (num_positive_weights + num_negative_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question:** How many weights are >= 0?  68419 (according to graphlab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with logistic regression\n",
    "**9.** Now that a model is trained, we can make predictions on the **test data**. In this section, we will explore this in the context of 3 data points/examples in the test dataset.  We refer to this set of 3 examples as the **sample_test_data**. Take the 11th, 12th, and 13th data points in the test data and save them to sample_test_data. Python's regular slicing syntax wont work - sample_test_data['review'][0], cause the indexes are those from test_data!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59    5\n",
      "71    2\n",
      "91    1\n",
      "Name: rating, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>5</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Wall Decor Removable Decal Sticker - Colorful ...</td>\n",
       "      <td>Would not purchase again or recommend. The dec...</td>\n",
       "      <td>2</td>\n",
       "      <td>Would not purchase again or recommend The deca...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>New Style Trailing Cherry Blossom Tree Decal R...</td>\n",
       "      <td>Was so excited to get this product for my baby...</td>\n",
       "      <td>1</td>\n",
       "      <td>Was so excited to get this product for my baby...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "59                          Our Baby Girl Memory Book   \n",
       "71  Wall Decor Removable Decal Sticker - Colorful ...   \n",
       "91  New Style Trailing Cherry Blossom Tree Decal R...   \n",
       "\n",
       "                                               review  rating  \\\n",
       "59  Absolutely love it and all of the Scripture in...       5   \n",
       "71  Would not purchase again or recommend. The dec...       2   \n",
       "91  Was so excited to get this product for my baby...       1   \n",
       "\n",
       "                                         review_clean  sentiment  \n",
       "59  Absolutely love it and all of the Scripture in...          1  \n",
       "71  Would not purchase again or recommend The deca...         -1  \n",
       "91  Was so excited to get this product for my baby...         -1  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data = test_data[10:13]  #samples/rows 10,11,12\n",
    "print sample_test_data['rating']   # Please NB row indices - use that with iloc!!\n",
    "sample_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dig deeper into the first row of the **sample_test_data**. Here's the full review:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good time to review Different Choices for Indexing for dataframes, [see] (http://pandas.pydata.org/pandas-docs/stable/indexing.html)\n",
    "\n",
    "**.loc is primarily label based**, but may also be used with a boolean array. .loc will raise KeyError when the items are not found. Allowed inputs are:\n",
    "\n",
    "*    A single label, e.g. 5 or 'a', (note that **in this context 5 is interpreted as a label of the index. This use is not an integer position along the index)**\n",
    "*    A list or array of labels ['a', 'b', 'c']\n",
    "*    A slice object with labels 'a':'f', (note that contrary to usual python slices, both the start and the stop are included!)\n",
    "*    A boolean array e.g products[ products['rating'] != 3 ]\n",
    "*    A callable function with one argument (the calling Series, DataFrame or Panel) and that returns valid output for indexing (one of the above)\n",
    "\n",
    "**.iloc is primarily integer position based (from 0 to length-1 of the axis)**, but may also be used with a boolean array. .iloc will raise IndexError if a requested indexer is out-of-bounds, except slice indexers which allow out-of-bounds indexing. (this conforms with python/numpy slice semantics). Allowed inputs are:\n",
    "\n",
    "*    An integer e.g. 5, its interpreted as an integer position along the index\n",
    "*    A list or array of integers [4, 3, 0] e.g train_data = products.iloc[train_idx, :], where train_idx is a list of integer indices.\n",
    "*    A slice object with ints e.g 1:7  --> test_data[10:13]\n",
    "*    A boolean array e.g products[products['sentiment'] == -1]\n",
    "*    A callable function with one argument (the calling Series, DataFrame or Panel) and that returns valid output for indexing (one of the above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely love it and all of the Scripture in it.  I purchased the Baby Boy version for my grandson when he was born and my daughter-in-law was thrilled to receive the same book again.\n",
      "Absolutely love it and all of the Scripture in it.  I purchased the Baby Boy version for my grandson when he was born and my daughter-in-law was thrilled to receive the same book again.\n",
      "Absolutely love it and all of the Scripture in it.  I purchased the Baby Boy version for my grandson when he was born and my daughter-in-law was thrilled to receive the same book again.\n",
      "Series([], Name: review, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# sample_test_data[59]['review']      #KeyError: 59\n",
    "# sample_test_data[0]['review']       #KeyError:  0\n",
    "\n",
    "print sample_test_data.loc[59]['review'] \n",
    "# sample_test_data.iloc[59]['review']\n",
    "# IndexError: single positional indexer is out-of-bounds\n",
    "\n",
    "# Use iloc for positional indexing\n",
    "print sample_test_data.iloc[0]['review']\n",
    "\n",
    "# print sample_test_data.loc[0]['review'] \n",
    "# KeyError: 'the label [0] is not in the [index]'\n",
    "\n",
    "print sample_test_data['review'][59]\n",
    "print sample_test_data['review'][59:60]\n",
    "\n",
    "# see http://www.gregreda.com/2013/10/26/working-with-pandas-dataframes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That review seems pretty positive.\n",
    "\n",
    "Now, let's see what the next row of the **sample_test_data** looks like. As we could guess from the sentiment (-1), the review is quite negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Would not purchase again or recommend. The decals were thick almost plastic like and were coming off the wall as I was applying them! The would NOT stick! Literally stayed stuck for about 5 minutes then started peeling off.'"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data['review'][71]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10.** We will now make a **class** prediction for the **sample_test_data**. The `sentiment_model` should predict **+1** if the sentiment is positive and **-1** if the sentiment is negative. Recall from the lecture that the **score** (sometimes called **margin**) for the logistic regression model  is defined as:\n",
    "\n",
    "$$\n",
    "\\mbox{score}_i = \\mathbf{w}^T h(\\mathbf{x}_i)\n",
    "$$ \n",
    "\n",
    "where $h(\\mathbf{x}_i)$ represents the features for example $i$.  We will write some code to obtain the **scores** using GraphLab Create. For each row, the **score** (or margin) is a number in the range **[-inf, inf]**. Note that scores is just a dot product of weights and features as in regression!! - so predicted values.\n",
    "\n",
    "Hint: need to convert sample_test_data into the sparse matrix format first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.60224818  -3.17079879 -10.42488847]\n"
     ]
    }
   ],
   "source": [
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# margin classfier --> margin=score, \n",
    "# score >= 0 on one side of margin, score<0 on other side of margin or decision boundary\n",
    "#scores = sentiment_model.predict(sample_test_data, output_type='margin')\n",
    "#print scores   \n",
    "#print scores.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting sentiment\n",
    "\n",
    "**11.** These scores can be used to make class predictions as follows:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & \\mathbf{w}^T h(\\mathbf{x}_i) > 0 \\\\\n",
    "      -1 & \\mathbf{w}^T h(\\mathbf{x}_i) \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Using scores, write code to calculate $\\hat{y}$, the class predictions: \n",
    "\n",
    "Again there are many ways to skin the goat!!! Given scores is just a list of values, we can either use an in place lambda function of list comprehension to do this in one line, show off both ways below. Traditioanlly we would iterate through the list and pick up item/value one by one, inspect if its neg or pos and the store/print corresponding -1 or +1. In both cases a list of outcomes is produced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'numpy.ndarray' object has no attribute 'apply'\n",
    "#predictions = scores.apply(lambda x : +1 if x > 0 else -1)  #lambda in place function\n",
    "#print predictions                                           #scores is SArray.dtype: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "#list comprehension  - optimized iterator through values in list, for each item do test\n",
    "predictions = [+1 if x > 0 else -1 for x in scores]    \n",
    "print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_class(model, data):\n",
    "    scores = list(model.decision_function(data))\n",
    "    score_class = [+1 if x > 0 else -1 for x in scores]\n",
    "    return (score_class)  #if no enclose return, prints None!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to verify that the class predictions obtained by your calculations are the same as that obtained from GraphLab Create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My class predictions:\n",
      "[1, -1, -1]\n",
      "Class predictions according to  scikit-learn:\n",
      "[ 1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print \"My class predictions:\"\n",
    "print predict_class(sentiment_model, sample_test_matrix )\n",
    "print \"Class predictions according to  scikit-learn:\" \n",
    "print sentiment_model.predict(sample_test_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Make sure your class predictions match with the ones obtained from sentiment_model. The logistic regression classifier in scikit-learn comes with the predict function for this purpose.\n",
    "\n",
    "### Probability predictions\n",
    "\n",
    "**12.** Recall from the lectures that we can also calculate the probability predictions from the scores using:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{Score})}.\n",
    "$$ $$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))}.\n",
    "$$\n",
    "\n",
    "Using the variable **scores** calculated previously, write code to calculate the probability that a sentiment is positive using the above formula. For each row, the probabilities should be a number in the range **[0, 1]**. \n",
    "\n",
    "Note that the probability values are for a prediction of positive sentiment (+1) given a specific value for featuere or input x and its weight/coefficient. so $$ P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) $$ \n",
    "We can easily find probability of a negative sentiment, just 1 - P(+1) !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.96324003e-01   4.02795251e-02   2.96835318e-05]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "probabilities = 1.0 * 1/(1 + np.exp(-scores))\n",
    "print probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**: Make sure your probability predictions match the ones obtained from  scikit-learn. Note Class predictions using GraphLab Create 'sentiment_model.predict(sample_test_data, output_type='probability')' gives $$ P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) $$ \n",
    "i.e probability of +ve review/+ve sentiment P(y=+1) given X and weights. sklearn provides probabilities for both class, 1st colum is probs for -ve class, 1nd col is probs for +ve class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predictions according to sklearn:\n",
      "[[  3.67599678e-03   9.96324003e-01]\n",
      " [  9.59720475e-01   4.02795251e-02]\n",
      " [  9.99970316e-01   2.96835318e-05]]\n",
      "\n",
      "Probability of +ve reviews [  9.96324003e-01   4.02795251e-02   2.96835318e-05]\n"
     ]
    }
   ],
   "source": [
    "print \"Class predictions according to sklearn:\" \n",
    "probs = sentiment_model.predict_proba(sample_test_matrix)\n",
    "print probs\n",
    "\n",
    "#\n",
    "#probabilities in 2nd column are for class 1 - +ve reviews, 1st col probs for -ve reviews\n",
    "print \"\\nProbability of +ve reviews\",probs[:,1] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quiz Question:** Of the three data points in **sample_test_data**, which one (first, second, or third) has the **lowest probability** of being classified as a positive review? **third** cause it has lowest value to power of -5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most positive (and negative) review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13.** We now turn to examining the full test dataset, **test_data**, and use GraphLab Create to form predictions on all of the test data points for faster performance.\n",
    "\n",
    "Using the `sentiment_model`, find the 20 reviews in the entire **test_data** with the **highest probability** of being classified as a **positive review**. We refer to these as the \"most positive reviews.\"\n",
    "\n",
    "To calculate these top-20 reviews, use the following steps:\n",
    "1.  Make probability predictions on **test_data** using the `sentiment_model`. (**Hint:** When you call `.predict` to make predictions on the test data, use option `output_type='probability'` to output the probability rather than just the most likely class.)\n",
    "2.  Sort the data according to those predictions and pick the top 20. (**Hint:** You can use the `.topk` method on an SFrame to find the top k rows sorted according to the value of a specified column.) sklearns predict_proba() outputs a n by 2 matrix, n samples and 1 col each for each of the two classes. In this case we can see from above code segment that the +ve class probabibilities are in 2nd col, and -ve class probs in col 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predict_proba() (3, 2)\n",
      "[[  2.15452332e-01   7.84547668e-01]\n",
      " [  7.64698063e-07   9.99999235e-01]\n",
      " [  6.67993225e-02   9.33200677e-01]]\n",
      "2nd col is prob for +ve class [ 0.78454767  0.99999924  0.93320068]\n",
      "\n",
      "Indices for probs sorted ascending [0 2 1]\n",
      "\n",
      "Actual Probs sorted ascending [ 0.78454767  0.93320068  0.99999924]\n",
      "\n",
      "Shape of predict_proba() (33336, 2)\n",
      "[[  2.15452332e-01   7.84547668e-01]\n",
      " [  7.64698063e-07   9.99999235e-01]\n",
      " [  6.67993225e-02   9.33200677e-01]\n",
      " ..., \n",
      " [  5.15140529e-06   9.99994849e-01]\n",
      " [  2.39182548e-06   9.99997608e-01]\n",
      " [  1.82340001e-02   9.81766000e-01]]\n",
      "2nd col is prob for +ve class [ 0.78454767  0.99999924  0.93320068 ...,  0.99999485  0.99999761  0.981766  ]\n",
      "\n",
      "Indices for probs sorted ascending [ 2931 21700 13939 ..., 18112 20743 15732]\n",
      "\n",
      "Actual Probs sorted ascending [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "#get 1st 3 predictions using test_matrix to test code\n",
    "prob_pred = sentiment_model.predict_proba(test_matrix)[0:3, ]\n",
    "print \"Shape of predict_proba()\", np.shape(prob_pred)    \n",
    "#5 predictions - 1 for each sample in test_matrix and prob pred are for both classes\n",
    "# which column is prediction for +ve class ???\n",
    "#prob_pred = prob_pred.tolist()   #no need for this, already a 2D numpy array\n",
    "\n",
    "print prob_pred\n",
    "\n",
    "prob_pred = prob_pred[:,1]   #assume 2nd col for +ve class, grab that only for sorting\n",
    "print \"2nd col is prob for +ve class\", prob_pred\n",
    "\n",
    "#sorts probabilities ascending order and gives indices of sorted list\n",
    "order = np.argsort(prob_pred)  \n",
    "print \"\\nIndices for probs sorted ascending\", order\n",
    "print \"\\nActual Probs sorted ascending\", prob_pred[order]\n",
    "\n",
    "\n",
    "#great - now apply to entire data set\n",
    "\n",
    "prob_pred = sentiment_model.predict_proba(test_matrix)\n",
    "print \"\\nShape of predict_proba()\", np.shape(prob_pred)    \n",
    "#33336 predictions - 1 for each sample and prob pred for both classes\n",
    "print prob_pred\n",
    "\n",
    "prob_pred = prob_pred[:,1]   #assume 2nd col for +ve class, grab that only for sorting\n",
    "print \"2nd col is prob for +ve class\", prob_pred\n",
    "\n",
    "order=np.argsort(prob_pred) \n",
    "print \"\\nIndices for probs sorted ascending\", order\n",
    "print \"\\nActual Probs sorted ascending\", prob_pred[order][-20:]\n",
    "#print test_data['review_clean'][order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of predict_proba() (33336, 2)\n",
      "2nd col is prob for +ve class [ 0.78454767  0.99999924  0.93320068 ...,  0.99999485  0.99999761  0.981766  ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172351</th>\n",
       "      <td>Phil &amp;amp; Teds Navigator Buggy Golden Kiwi Fr...</td>\n",
       "      <td>I\\'m pretty happy with this stroller. I use it...</td>\n",
       "      <td>4</td>\n",
       "      <td>Im pretty happy with this stroller I use it wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182089</th>\n",
       "      <td>Summer Infant Wide View Digital Color Video Mo...</td>\n",
       "      <td>I love this baby monitor.  I can compare this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this baby monitor  I can compare this o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165593</th>\n",
       "      <td>Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatwa...</td>\n",
       "      <td>For the price this set is unbelievable- and tr...</td>\n",
       "      <td>5</td>\n",
       "      <td>For the price this set is unbelievable and tru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133651</th>\n",
       "      <td>Britax 2012 B-Agile Stroller, Red</td>\n",
       "      <td>[I got this stroller for my daughter prior to ...</td>\n",
       "      <td>4</td>\n",
       "      <td>I got this stroller for my daughter prior to t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140816</th>\n",
       "      <td>Diono RadianRXT Convertible Car Seat, Plum</td>\n",
       "      <td>I bought this seat for my tall (38in) and thin...</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought this seat for my tall 38in and thin 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80155</th>\n",
       "      <td>Simple Wishes Hands-Free Breastpump Bra, Pink,...</td>\n",
       "      <td>I just tried this hands free breastpump bra, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>I just tried this hands free breastpump bra an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66059</th>\n",
       "      <td>Evenflo 6 Pack Classic Glass Bottle, 4-Ounce</td>\n",
       "      <td>It\\'s always fun to write a review on those pr...</td>\n",
       "      <td>5</td>\n",
       "      <td>Its always fun to write a review on those prod...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119182</th>\n",
       "      <td>Roan Rocco Classic Pram Stroller 2-in-1 with B...</td>\n",
       "      <td>Great Pram Rocco!!!!!!I bought this pram from ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great Pram RoccoI bought this pram from Europe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137034</th>\n",
       "      <td>Graco Pack \\'n Play Element Playard - Flint</td>\n",
       "      <td>My husband and I assembled this Pack n\\' Play ...</td>\n",
       "      <td>4</td>\n",
       "      <td>My husband and I assembled this Pack n Play la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180646</th>\n",
       "      <td>Mamas &amp;amp; Papas 2014 Urbo2 Stroller - Black</td>\n",
       "      <td>After much research I purchased an Urbo2. It\\'...</td>\n",
       "      <td>4</td>\n",
       "      <td>After much research I purchased an Urbo2 Its e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168697</th>\n",
       "      <td>Graco FastAction Fold Jogger Click Connect Str...</td>\n",
       "      <td>Graco\\'s FastAction Jogging Stroller definitel...</td>\n",
       "      <td>5</td>\n",
       "      <td>Gracos FastAction Jogging Stroller definitely ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50315</th>\n",
       "      <td>P\\'Kolino Silly Soft Seating in Tias, Green</td>\n",
       "      <td>I\\'ve purchased both the P\\'Kolino Little Read...</td>\n",
       "      <td>4</td>\n",
       "      <td>Ive purchased both the PKolino Little Reader C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168081</th>\n",
       "      <td>Buttons Cloth Diaper Cover - One Size - 8 Colo...</td>\n",
       "      <td>We are big Best Bottoms fans here, but I wante...</td>\n",
       "      <td>4</td>\n",
       "      <td>We are big Best Bottoms fans here but I wanted...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147949</th>\n",
       "      <td>Baby Jogger City Mini GT Single Stroller, Shad...</td>\n",
       "      <td>Amazing, Love, Love, Love it !!! All 5 STARS a...</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazing Love Love Love it  All 5 STARS all the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52631</th>\n",
       "      <td>Evenflo X Sport Plus Convenience Stroller - Ch...</td>\n",
       "      <td>After seeing this in Parent\\'s Magazine and re...</td>\n",
       "      <td>5</td>\n",
       "      <td>After seeing this in Parents Magazine and read...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22586</th>\n",
       "      <td>Britax Decathlon Convertible Car Seat, Tiffany</td>\n",
       "      <td>I researched a few different seats to put in o...</td>\n",
       "      <td>4</td>\n",
       "      <td>I researched a few different seats to put in o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97325</th>\n",
       "      <td>Freemie Hands-Free Concealable Breast Pump Col...</td>\n",
       "      <td>I absolutely love this product.  I work as a C...</td>\n",
       "      <td>5</td>\n",
       "      <td>I absolutely love this product  I work as a Cu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100166</th>\n",
       "      <td>Infantino Wrap and Tie Baby Carrier, Black Blu...</td>\n",
       "      <td>I bought this carrier when my daughter was abo...</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought this carrier when my daughter was abo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114796</th>\n",
       "      <td>Fisher-Price Cradle \\'N Swing,  My Little Snug...</td>\n",
       "      <td>My husband and I cannot state enough how much ...</td>\n",
       "      <td>5</td>\n",
       "      <td>My husband and I cannot state enough how much ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87017</th>\n",
       "      <td>Baby Einstein Around The World Discovery Center</td>\n",
       "      <td>I am so HAPPY I brought this item for my 7 mon...</td>\n",
       "      <td>5</td>\n",
       "      <td>I am so HAPPY I brought this item for my 7 mon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "172351  Phil &amp; Teds Navigator Buggy Golden Kiwi Fr...   \n",
       "182089  Summer Infant Wide View Digital Color Video Mo...   \n",
       "165593  Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatwa...   \n",
       "133651                  Britax 2012 B-Agile Stroller, Red   \n",
       "140816         Diono RadianRXT Convertible Car Seat, Plum   \n",
       "80155   Simple Wishes Hands-Free Breastpump Bra, Pink,...   \n",
       "66059        Evenflo 6 Pack Classic Glass Bottle, 4-Ounce   \n",
       "119182  Roan Rocco Classic Pram Stroller 2-in-1 with B...   \n",
       "137034        Graco Pack \\'n Play Element Playard - Flint   \n",
       "180646      Mamas &amp; Papas 2014 Urbo2 Stroller - Black   \n",
       "168697  Graco FastAction Fold Jogger Click Connect Str...   \n",
       "50315         P\\'Kolino Silly Soft Seating in Tias, Green   \n",
       "168081  Buttons Cloth Diaper Cover - One Size - 8 Colo...   \n",
       "147949  Baby Jogger City Mini GT Single Stroller, Shad...   \n",
       "52631   Evenflo X Sport Plus Convenience Stroller - Ch...   \n",
       "22586      Britax Decathlon Convertible Car Seat, Tiffany   \n",
       "97325   Freemie Hands-Free Concealable Breast Pump Col...   \n",
       "100166  Infantino Wrap and Tie Baby Carrier, Black Blu...   \n",
       "114796  Fisher-Price Cradle \\'N Swing,  My Little Snug...   \n",
       "87017     Baby Einstein Around The World Discovery Center   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "172351  I\\'m pretty happy with this stroller. I use it...       4   \n",
       "182089  I love this baby monitor.  I can compare this ...       5   \n",
       "165593  For the price this set is unbelievable- and tr...       5   \n",
       "133651  [I got this stroller for my daughter prior to ...       4   \n",
       "140816  I bought this seat for my tall (38in) and thin...       5   \n",
       "80155   I just tried this hands free breastpump bra, a...       5   \n",
       "66059   It\\'s always fun to write a review on those pr...       5   \n",
       "119182  Great Pram Rocco!!!!!!I bought this pram from ...       5   \n",
       "137034  My husband and I assembled this Pack n\\' Play ...       4   \n",
       "180646  After much research I purchased an Urbo2. It\\'...       4   \n",
       "168697  Graco\\'s FastAction Jogging Stroller definitel...       5   \n",
       "50315   I\\'ve purchased both the P\\'Kolino Little Read...       4   \n",
       "168081  We are big Best Bottoms fans here, but I wante...       4   \n",
       "147949  Amazing, Love, Love, Love it !!! All 5 STARS a...       5   \n",
       "52631   After seeing this in Parent\\'s Magazine and re...       5   \n",
       "22586   I researched a few different seats to put in o...       4   \n",
       "97325   I absolutely love this product.  I work as a C...       5   \n",
       "100166  I bought this carrier when my daughter was abo...       5   \n",
       "114796  My husband and I cannot state enough how much ...       5   \n",
       "87017   I am so HAPPY I brought this item for my 7 mon...       5   \n",
       "\n",
       "                                             review_clean  sentiment  \n",
       "172351  Im pretty happy with this stroller I use it wi...          1  \n",
       "182089  I love this baby monitor  I can compare this o...          1  \n",
       "165593  For the price this set is unbelievable and tru...          1  \n",
       "133651  I got this stroller for my daughter prior to t...          1  \n",
       "140816  I bought this seat for my tall 38in and thin 2...          1  \n",
       "80155   I just tried this hands free breastpump bra an...          1  \n",
       "66059   Its always fun to write a review on those prod...          1  \n",
       "119182  Great Pram RoccoI bought this pram from Europe...          1  \n",
       "137034  My husband and I assembled this Pack n Play la...          1  \n",
       "180646  After much research I purchased an Urbo2 Its e...          1  \n",
       "168697  Gracos FastAction Jogging Stroller definitely ...          1  \n",
       "50315   Ive purchased both the PKolino Little Reader C...          1  \n",
       "168081  We are big Best Bottoms fans here but I wanted...          1  \n",
       "147949  Amazing Love Love Love it  All 5 STARS all the...          1  \n",
       "52631   After seeing this in Parents Magazine and read...          1  \n",
       "22586   I researched a few different seats to put in o...          1  \n",
       "97325   I absolutely love this product  I work as a Cu...          1  \n",
       "100166  I bought this carrier when my daughter was abo...          1  \n",
       "114796  My husband and I cannot state enough how much ...          1  \n",
       "87017   I am so HAPPY I brought this item for my 7 mon...          1  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_pred = sentiment_model.predict_proba(test_matrix)\n",
    "print \"\\nShape of predict_proba()\", np.shape(prob_pred)    \n",
    "\n",
    "prob_pred = prob_pred[:,1]   #assume 2nd col for +ve class, grab that only for sorting\n",
    "print \"2nd col is prob for +ve class\", prob_pred\n",
    "\n",
    "order = np.argsort(prob_pred)   #sort lowest to highest prob\n",
    "\n",
    "#now we have list of indices for rows test matrix with highest prob +ve review\n",
    "top20_indx = order[-20:]  \n",
    "test_data.iloc[top20_indx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which of the following products are represented in the 20 most positive reviews? [multiple choice]\n",
    "\n",
    "Now, let us repeat this excercise to find the \"most negative reviews.\" Use the prediction probabilities to find the  20 reviews in the **test_data** with the **lowest probability** of being classified as a **positive review**. Repeat the same steps above but make sure you **sort in the opposite order**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16042</th>\n",
       "      <td>Fisher-Price Ocean Wonders Aquarium Bouncer</td>\n",
       "      <td>We have not had ANY luck with Fisher-Price pro...</td>\n",
       "      <td>2</td>\n",
       "      <td>We have not had ANY luck with FisherPrice prod...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120209</th>\n",
       "      <td>Levana Safe N\\'See Digital Video Baby Monitor ...</td>\n",
       "      <td>This is the first review I have ever written o...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is the first review I have ever written o...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77072</th>\n",
       "      <td>Safety 1st Exchangeable Tip 3 in 1 Thermometer</td>\n",
       "      <td>I thought it sounded great to have different t...</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought it sounded great to have different t...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48694</th>\n",
       "      <td>Adiri BPA Free Natural Nurser Ultimate Bottle ...</td>\n",
       "      <td>I will try to write an objective review of the...</td>\n",
       "      <td>2</td>\n",
       "      <td>I will try to write an objective review of the...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155287</th>\n",
       "      <td>VTech Communications Safe &amp;amp; Sounds Full Co...</td>\n",
       "      <td>This is my second video monitoring system, the...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is my second video monitoring system the ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94560</th>\n",
       "      <td>The First Years True Choice P400 Premium Digit...</td>\n",
       "      <td>Note: we never installed batteries in these un...</td>\n",
       "      <td>1</td>\n",
       "      <td>Note we never installed batteries in these uni...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53207</th>\n",
       "      <td>Safety 1st High-Def Digital Monitor</td>\n",
       "      <td>We bought this baby monitor to replace a diffe...</td>\n",
       "      <td>1</td>\n",
       "      <td>We bought this baby monitor to replace a diffe...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81332</th>\n",
       "      <td>Cloth Diaper Sprayer--styles may vary</td>\n",
       "      <td>I bought this sprayer out of desperation durin...</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this sprayer out of desperation durin...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10677</th>\n",
       "      <td>Philips AVENT Newborn Starter Set</td>\n",
       "      <td>It\\'s 3am in the morning and needless to say, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Its 3am in the morning and needless to say thi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113995</th>\n",
       "      <td>Motorola Digital Video Baby Monitor with Room ...</td>\n",
       "      <td>DO NOT BUY THIS BABY MONITOR!I purchased this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>DO NOT BUY THIS BABY MONITORI purchased this m...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59546</th>\n",
       "      <td>Ellaroo Mei Tai Baby Carrier - Hershey</td>\n",
       "      <td>This is basically an overpriced piece of fabri...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is basically an overpriced piece of fabri...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9915</th>\n",
       "      <td>Cosco Alpha Omega Elite Convertible Car Seat</td>\n",
       "      <td>I bought this car seat after both seeing  the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this car seat after both seeing  the ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40079</th>\n",
       "      <td>Chicco Cortina KeyFit 30 Travel System in Adve...</td>\n",
       "      <td>My wife and I have used this system in two car...</td>\n",
       "      <td>1</td>\n",
       "      <td>My wife and I have used this system in two car...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172090</th>\n",
       "      <td>Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...</td>\n",
       "      <td>I read so many reviews saying the Belkin WiFi ...</td>\n",
       "      <td>2</td>\n",
       "      <td>I read so many reviews saying the Belkin WiFi ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75994</th>\n",
       "      <td>Peg-Perego Tatamia High Chair, White Latte</td>\n",
       "      <td>I can see why there are so many good reviews o...</td>\n",
       "      <td>2</td>\n",
       "      <td>I can see why there are so many good reviews o...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149987</th>\n",
       "      <td>NUK Cook-n-Blend Baby Food Maker</td>\n",
       "      <td>It thought this would be great. I did a lot of...</td>\n",
       "      <td>1</td>\n",
       "      <td>It thought this would be great I did a lot of ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154878</th>\n",
       "      <td>VTech Communications Safe &amp;amp; Sound Digital ...</td>\n",
       "      <td>First, the distance on these are no more than ...</td>\n",
       "      <td>1</td>\n",
       "      <td>First the distance on these are no more than 7...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>Safety 1st Deluxe 4-in-1 Bath Station</td>\n",
       "      <td>This item is junk.  I originally chose it beca...</td>\n",
       "      <td>1</td>\n",
       "      <td>This item is junk  I originally chose it becau...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31741</th>\n",
       "      <td>Regalo My Cot Portable Bed, Royal Blue</td>\n",
       "      <td>If I could give this product zero stars I woul...</td>\n",
       "      <td>1</td>\n",
       "      <td>If I could give this product zero stars I woul...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83234</th>\n",
       "      <td>Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs</td>\n",
       "      <td>My Experience: Babykicks Inserts failure vs RA...</td>\n",
       "      <td>5</td>\n",
       "      <td>My Experience Babykicks Inserts failure vs RAV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "16042         Fisher-Price Ocean Wonders Aquarium Bouncer   \n",
       "120209  Levana Safe N\\'See Digital Video Baby Monitor ...   \n",
       "77072      Safety 1st Exchangeable Tip 3 in 1 Thermometer   \n",
       "48694   Adiri BPA Free Natural Nurser Ultimate Bottle ...   \n",
       "155287  VTech Communications Safe &amp; Sounds Full Co...   \n",
       "94560   The First Years True Choice P400 Premium Digit...   \n",
       "53207                 Safety 1st High-Def Digital Monitor   \n",
       "81332               Cloth Diaper Sprayer--styles may vary   \n",
       "10677                   Philips AVENT Newborn Starter Set   \n",
       "113995  Motorola Digital Video Baby Monitor with Room ...   \n",
       "59546              Ellaroo Mei Tai Baby Carrier - Hershey   \n",
       "9915         Cosco Alpha Omega Elite Convertible Car Seat   \n",
       "40079   Chicco Cortina KeyFit 30 Travel System in Adve...   \n",
       "172090  Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...   \n",
       "75994          Peg-Perego Tatamia High Chair, White Latte   \n",
       "149987                   NUK Cook-n-Blend Baby Food Maker   \n",
       "154878  VTech Communications Safe &amp; Sound Digital ...   \n",
       "1116                Safety 1st Deluxe 4-in-1 Bath Station   \n",
       "31741              Regalo My Cot Portable Bed, Royal Blue   \n",
       "83234       Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "16042   We have not had ANY luck with Fisher-Price pro...       2   \n",
       "120209  This is the first review I have ever written o...       1   \n",
       "77072   I thought it sounded great to have different t...       1   \n",
       "48694   I will try to write an objective review of the...       2   \n",
       "155287  This is my second video monitoring system, the...       1   \n",
       "94560   Note: we never installed batteries in these un...       1   \n",
       "53207   We bought this baby monitor to replace a diffe...       1   \n",
       "81332   I bought this sprayer out of desperation durin...       1   \n",
       "10677   It\\'s 3am in the morning and needless to say, ...       1   \n",
       "113995  DO NOT BUY THIS BABY MONITOR!I purchased this ...       1   \n",
       "59546   This is basically an overpriced piece of fabri...       1   \n",
       "9915    I bought this car seat after both seeing  the ...       1   \n",
       "40079   My wife and I have used this system in two car...       1   \n",
       "172090  I read so many reviews saying the Belkin WiFi ...       2   \n",
       "75994   I can see why there are so many good reviews o...       2   \n",
       "149987  It thought this would be great. I did a lot of...       1   \n",
       "154878  First, the distance on these are no more than ...       1   \n",
       "1116    This item is junk.  I originally chose it beca...       1   \n",
       "31741   If I could give this product zero stars I woul...       1   \n",
       "83234   My Experience: Babykicks Inserts failure vs RA...       5   \n",
       "\n",
       "                                             review_clean  sentiment  \n",
       "16042   We have not had ANY luck with FisherPrice prod...         -1  \n",
       "120209  This is the first review I have ever written o...         -1  \n",
       "77072   I thought it sounded great to have different t...         -1  \n",
       "48694   I will try to write an objective review of the...         -1  \n",
       "155287  This is my second video monitoring system the ...         -1  \n",
       "94560   Note we never installed batteries in these uni...         -1  \n",
       "53207   We bought this baby monitor to replace a diffe...         -1  \n",
       "81332   I bought this sprayer out of desperation durin...         -1  \n",
       "10677   Its 3am in the morning and needless to say thi...         -1  \n",
       "113995  DO NOT BUY THIS BABY MONITORI purchased this m...         -1  \n",
       "59546   This is basically an overpriced piece of fabri...         -1  \n",
       "9915    I bought this car seat after both seeing  the ...         -1  \n",
       "40079   My wife and I have used this system in two car...         -1  \n",
       "172090  I read so many reviews saying the Belkin WiFi ...         -1  \n",
       "75994   I can see why there are so many good reviews o...         -1  \n",
       "149987  It thought this would be great I did a lot of ...         -1  \n",
       "154878  First the distance on these are no more than 7...         -1  \n",
       "1116    This item is junk  I originally chose it becau...         -1  \n",
       "31741   If I could give this product zero stars I woul...         -1  \n",
       "83234   My Experience Babykicks Inserts failure vs RAV...          1  "
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we have list of indices for rows test matrix with lowest prob +ve review\n",
    "lowest20_indx = order[0:20]  \n",
    "test_data.iloc[lowest20_indx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of predict_proba() (33336, 2)\n",
      "1st col is prob for -ve class [  2.15452332e-01   7.64698063e-07   6.67993225e-02 ...,   5.15140529e-06\n",
      "   2.39182548e-06   1.82340001e-02]\n"
     ]
    }
   ],
   "source": [
    "# or alternatively sort the probability on -ve class lowest to highest\n",
    "# and last 20 will with those with highest prob for being a -ve review\n",
    "# Gives same result as reviews with lowest prob being +ve\n",
    "\n",
    "prob_pred = sentiment_model.predict_proba(test_matrix)\n",
    "print \"\\nShape of predict_proba()\", np.shape(prob_pred)    \n",
    "\n",
    "prob_pred = prob_pred[:,0]   #assume 2nd col for +ve class, grab that only for sorting\n",
    "print \"1st col is prob for -ve class\", prob_pred\n",
    "\n",
    "order = np.argsort(prob_pred)   #sort lowest to highest prob\n",
    "\n",
    "#now we have list of indices for rows test matrix with highest prob -ve review\n",
    "top20_indx = order[-20:]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to show that both lists conatin same row indices. An easy (and quick) way to determine if two unordered lists contain the same elements. Python has a built-in datatype for an unordered collection of (hashable) things, called a set. If you convert both lists to sets, the comparison will be unordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(lowest20_indx) == set(top20_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True], dtype=bool)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternativley \n",
    "lowest20_indx.sort()\n",
    "top20_indx.sort()\n",
    "lowest20_indx == top20_indx\n",
    "\n",
    "#test_data.iloc[top20_indx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Quiz Question**: Which of the following products are represented in the 20 most negative reviews?  [multiple choice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute accuracy of the classifier\n",
    "\n",
    "We will now evaluate the accuracy of the trained classifer. Recall that the accuracy is given by\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "This can be computed as follows:\n",
    "\n",
    "* **Step 1:** Use the trained model to compute class predictions (**Hint:** Use the `predict` method)\n",
    "* **Step 2:** Count the number of data points when the predicted class labels match the ground truth labels (called `true_labels` below).\n",
    "* **Step 3:** Divide the total number of correct predictions by the total number of data points in the dataset.\n",
    "\n",
    "Complete the function below to compute the classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nMany ways to do it \\n1.Get margin or scores and predict which side of decision bounday each sample falls\\nby looking at the sign (+ve/-ve) of the score for each data point\\n\\n  scores = model.predict(data, output_type='margin')\\n  predicted_labels = [+1 if x > 0 else -1 for x in scores]\\n\\n2.Get probabilities that a given sample is a +ve setiment given sample and weights\\nand if prob >= 0.5, assign +ve +1 sentiment, -ve -1 otherwise\\n\\n  probs = model.predict(data, output_type='probability')\\n  predicted_labels = [+1 if x >= 0.5 else -1 for x in probs]\\n\\n3. Easiest - get prediction in form of class labels +1 or -1\\ndefault output of model.predict is class predictions\\n\\n  predicted_labels =  model.predict(data, output_type='class')  \\n  \\n\""
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    '''\n",
    "    Many ways to do it \n",
    "    1.Get margin or scores and predict which side of decision bounday each sample falls\n",
    "    by looking at the sign (+ve/-ve) of the score for each data point\n",
    "    \n",
    "      scores = model.predict(data, output_type='margin')\n",
    "      predicted_labels = [+1 if x > 0 else -1 for x in scores]\n",
    "    \n",
    "    2.Get probabilities that a given sample is a +ve setiment given sample and weights\n",
    "    and if prob >= 0.5, assign +ve +1 sentiment, -ve -1 otherwise\n",
    "    \n",
    "      probs = model.predict(data, output_type='probability')\n",
    "      predicted_labels = [+1 if x >= 0.5 else -1 for x in probs]\n",
    "    \n",
    "    3. Easiest - get prediction in form of class labels +1 or -1\n",
    "    default output of model.predict is class predictions\n",
    "    \n",
    "      predicted_labels =  model.predict(data, output_type='class')  \n",
    "      \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(model, data, true_labels):\n",
    "    # First get the predictions\n",
    "    predicted_labels =  model.predict(data) \n",
    "    \n",
    "    # Compute the number of correctly classified examples\n",
    "    # understand why this will always give num of data points regardless True/False\n",
    "    # 1st to element-wise boolean comparision between the 2 arrays \n",
    "    # and then count how many comparisions returned True, i.e same class in both array !! \n",
    "    # but doesn't work - in fact (predicted_labels == true_labels) outputs 1s and 0s!!!!\n",
    "    #print \"num_correct using len()\", len ( (predicted_labels == true_labels) == 'True' )\n",
    "    print \"num_correct using '(predicted_labels == true_labels).sum()' = \",\\\n",
    "    (predicted_labels == true_labels).sum() \n",
    "    #sum gives correct result as same as counting # of 1s, 1+0+1+0+0=2!!\n",
    "    \n",
    "    # np.equal(x1,x2) -- > Return (x1 == x2) element-wise\n",
    "    # Parameters:\t x1, x2 : array_like : Input arrays of the same shape.\n",
    "    # Returns:\t  out : ndarray or bool :  Output array of bools, or a single bool if x1 and x2 are scalars.  \n",
    "    \n",
    "    num_correct = sum ( np.equal(predicted_labels, true_labels) )\n",
    "    print \"num_correct using 'sum ( np.equal(predicted_labels, true_labels) )' = \", num_correct\n",
    "    print \"num_data\", data.shape[0]\n",
    "    \n",
    "    # Then compute accuracy by dividing num_correct by total number of examples\n",
    "    accuracy = num_correct * 1.0/data.shape[0]\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the classification accuracy of the **sentiment_model** on the **test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_correct using '(predicted_labels == true_labels).sum()' =  31078\n",
      "num_correct using 'sum ( np.equal(predicted_labels, true_labels) )' =  31078\n",
      "num_data 33336\n",
      "Accuracy = 0.93\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy = %0.2f\" %get_classification_accuracy(sentiment_model, test_matrix, test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: What is the accuracy of the **sentiment_model** on the **test_data**? Round your answer to 2 decimal places (e.g. 0.76). **0.91 from graphlab, 0.93 from sklearn**\n",
    "\n",
    "**Quiz Question**: Does a higher accuracy value on the **training_data** always imply that the classifier is better? **No**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn another classifier with fewer words\n",
    "\n",
    "There were a lot of words in the model we trained above. We will now train a simpler logistic regression model using only a subet of words that occur in the reviews. For this assignment, we selected a 20 words to work with. These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype_dict = {'name':str, 'review':str, 'rating':int}\n",
    "products = pd.read_csv('../../course-1/Week3/amazon_baby.csv', dtype = dtype_dict)\n",
    "\n",
    "products = products.fillna({'review':''})  # fill in N/A's in the review column\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation) \n",
    "\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
    "\n",
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "len(products) == len ( products[products['sentiment'] == -1]) + \\\n",
    "                len ( products[products['sentiment'] == 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(significant_words)\n",
    "\n",
    "for word in significant_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>love</th>\n",
       "      <th>great</th>\n",
       "      <th>easy</th>\n",
       "      <th>old</th>\n",
       "      <th>little</th>\n",
       "      <th>...</th>\n",
       "      <th>broke</th>\n",
       "      <th>less</th>\n",
       "      <th>even</th>\n",
       "      <th>waste</th>\n",
       "      <th>disappointed</th>\n",
       "      <th>work</th>\n",
       "      <th>product</th>\n",
       "      <th>money</th>\n",
       "      <th>would</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "      <td>These flannel wipes are OK but in my opinion n...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  \\\n",
       "0  Planetwise Flannel Wipes   \n",
       "1     Planetwise Wipe Pouch   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  These flannel wipes are OK, but in my opinion ...       3   \n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "\n",
       "                                        review_clean  sentiment  love  great  \\\n",
       "0  These flannel wipes are OK but in my opinion n...         -1     0      0   \n",
       "1  it came early and was not disappointed i love ...          1     1      0   \n",
       "\n",
       "   easy  old  little   ...    broke  less  even  waste  disappointed  work  \\\n",
       "0     0    0       0   ...        0     0     0      0             0     0   \n",
       "1     0    0       0   ...        0     0     0      0             1     0   \n",
       "\n",
       "   product  money  would  return  \n",
       "0        0      0      0       0  \n",
       "1        0      0      0       0  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each review, we will use the **word_count** column and trim out all words that are **not** in the **significant_words** list above. We will use the [SArray dictionary trim by keys functionality]( https://dato.com/products/create/docs/generated/graphlab.SArray.dict_trim_by_keys.html). Note that we are performing this on both the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, label):\n",
    "    data_sframe['intercept'] = 1\n",
    "    features = ['intercept'] + features\n",
    "    features_sframe = data_sframe[features]\n",
    "    feature_matrix = features_sframe.as_matrix()  #.to_numpy() if using SFrame\n",
    "    label_sarray = data_sframe[label]\n",
    "    label_array = label_sarray.as_matrix()\n",
    "    return(feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133416\n",
      "33336\n"
     ]
    }
   ],
   "source": [
    "#train_data['word_count_subset'] = train_data['word_count'].dict_trim_by_keys(significant_words, exclude=False)\n",
    "#test_data['word_count_subset'] = test_data['word_count'].dict_trim_by_keys(significant_words, exclude=False)\n",
    "\n",
    "# Use iloc for positional indexing\n",
    "\n",
    "train_data = products.iloc[train_idx,:]\n",
    "test_data = products.iloc[test_idx,:]\n",
    "print len(train_data)  #133416\n",
    "print len(test_data)   #33336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/win-data/shared/stats-R/anaconda2/envs/conda_py2.7/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Warning: This may take a few minutes...\n",
    "feature_matrix_train, sentiment = get_numpy_data(train_data, significant_words, 'sentiment') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133416, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [1, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print feature_matrix_train.shape\n",
    "feature_matrix_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the first 5 samples in train dataset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    These flannel wipes are OK, but in my opinion ...\n",
       "1    it came early and was not disappointed. i love...\n",
       "2    Very soft and comfortable and warmer than it l...\n",
       "3    This is a product well worth the purchase.  I ...\n",
       "4    All of my kids have cried non-stop when I trie...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0:5]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   love  great  easy  old  little  perfect  loves  well  able  car  broke  \\\n",
      "0     0      0     0    0       0        0      0     0     0    0      0   \n",
      "1     1      0     0    0       0        0      0     0     0    0      0   \n",
      "2     0      0     0    0       0        0      0     0     0    0      0   \n",
      "3     2      0     0    0       1        0      1     1     0    0      0   \n",
      "4     0      1     1    0       0        0      0     0     0    0      0   \n",
      "\n",
      "   less  even  waste  disappointed  work  product  money  would  return  \n",
      "0     0     0      0             0     0        0      0      0       0  \n",
      "1     0     0      0             1     0        0      0      0       0  \n",
      "2     0     0      0             0     0        0      0      0       0  \n",
      "3     0     0      0             0     0        2      0      0       0  \n",
      "4     0     0      0             0     1        0      0      0       0  \n"
     ]
    }
   ],
   "source": [
    "# To select multiple columns, simply pass a list of column names to the DataFrame, \n",
    "# the output of which will be a DataFrame.\n",
    "print train_data[significant_words].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **word_count** column in the graphlab version has been replaced by 20 columns here, each column has count for num of times that word appears in a given review - Inspect and you will see that the feature_matrix_train is similar to train_data[significant_words] with index series and col header removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 2, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix_train[0:5,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only working with a subet of these words, the column **word_count_subset** is a subset of the above dictionary. In this example, only 2 `significant words` are present in this review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a logistic regression model on a subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build a classifier with **word_count_subset** as the feature and **sentiment** as the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79337560712358335"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# instantiate a logistic regression model, and fit with X and y\n",
    "# X -> sparse matrix where each row is the word count vector for the corresponding review\n",
    "simple_model = LogisticRegression()\n",
    "X = feature_matrix_train\n",
    "y = train_data['sentiment']\n",
    "simple_model = model.fit(X, y)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "simple_model.score(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the classification accuracy using the `get_classification_accuracy` function you implemented earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(model, data, true_labels):\n",
    "    # First get the predictions\n",
    "    predicted_labels =  model.predict(data) \n",
    "    num_correct = sum ( np.equal(predicted_labels, true_labels) )\n",
    "    print \"num_correct using 'sum ( np.equal(predicted_labels, true_labels) )' = \", num_correct\n",
    "    print \"num_data\", data.shape[0]\n",
    "    \n",
    "    # Then compute accuracy by dividing num_correct by total number of examples\n",
    "    accuracy = num_correct * 1.0/data.shape[0]\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_correct using 'sum ( np.equal(predicted_labels, true_labels) )' =  26499\n",
      "num_data 33336\n",
      "Accuracy = 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/win-data/shared/stats-R/anaconda2/envs/conda_py2.7/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "feature_matrix_test, sentiment = get_numpy_data(test_data, significant_words, 'sentiment') \n",
    "print \"Accuracy = %0.2f\" \\\n",
    "   %get_classification_accuracy(simple_model, feature_matrix_test, test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will inspect the weights (coefficients) of the **simple_model**:\n",
    "Let's sort the coefficients (in descending order) by the **value** to obtain the coefficients with the most positive effect on the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.46044587  1.02488403  0.62013718  0.80331622  0.11968815  0.26750161\n",
      "   1.22672349  1.37217446  0.35096804  0.07555701  0.07830785 -1.41858188\n",
      "  -0.20979965 -0.37127294 -1.61151138 -2.05293832 -0.59327438 -0.18733665\n",
      "  -0.64718732 -0.36617285 -1.76055177]]\n",
      "Non zero coefficients (including intercept) =  22\n",
      "simple_model.coef_.shape: (1, 21)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sort' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-379-e2afdc385146>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"simple_model.coef_.shape:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimple_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sort' is not defined"
     ]
    }
   ],
   "source": [
    "print simple_model.coef_\n",
    "print \"Non zero coefficients (including intercept) = \" , \\\n",
    "np.count_nonzero(simple_model.coef_) + np.count_nonzero(simple_model.intercept_)\n",
    "\n",
    "print \"simple_model.coef_.shape:\", simple_model.coef_.shape\n",
    "\n",
    "print sort(simple_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Consider the coefficients of **simple_model**. There should be 21 of them, an intercept term + one for each word in **significant_words**. How many of the 20 coefficients (corresponding to the 20 **significant_words** and *excluding the intercept term*) are positive for the `simple_model`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sum(1 for x in simple_model.coef_[0] if x > 0), \\\n",
    "     len([x for x in simple_model.coef_[0] if x > 0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Are the positive words in the **simple_model** (let us call them `positive_significant_words`) also positive words in the **sentiment_model**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_significant_words = simple_model.coefficients [simple_model.coefficients['value'] > 0 ]['index']\n",
    "print positive_significant_words\n",
    "\n",
    "simple_positive = simple_model.coefficients.sort('value', ascending=False)\n",
    "simple_positive = simple_positive [simple_positive['value'] > 0 ]['index']\n",
    "\n",
    "setimental_positive = sentiment_model.coefficients.sort('value', ascending=False)\n",
    "sentiment_positive = setimental_positive [setimental_positive['value'] > 0 ]['index']\n",
    "\n",
    "print len(simple_positive)\n",
    "print len(sentiment_positive)\n",
    "simple_positive = simple_positive.to_numpy()\n",
    "sentiment_positive = sentiment_positive.to_numpy()\n",
    "print \"These words have positive weights in both the models\\n\", np.intersect1d(simple_positive, sentiment_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compare the accuracy of the **sentiment_model** and the **simple_model** using the `get_classification_accuracy` method you implemented above.\n",
    "\n",
    "First, compute the classification accuracy of the **sentiment_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_classification_accuracy(sentiment_model, train_data, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compute the classification accuracy of the **simple_model** on the **train_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_classification_accuracy(simple_model, train_data, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TRAINING set? **sentiment_model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will repeat this excercise on the **test_data**. Start by computing the classification accuracy of the **sentiment_model** on the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_classification_accuracy(sentiment_model, test_data, test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will compute the classification accuracy of the **simple_model** on the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_classification_accuracy(simple_model, test_data, test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Which model (**sentiment_model** or **simple_model**) has higher accuracy on the TEST set? **sentiment_model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Majority class prediction\n",
    "\n",
    "It is quite common to use the **majority class classifier** as the a baseline (or reference) model for comparison with your classifier model. The majority classifier model predicts the majority class for all data points. At the very least, you should healthily beat the majority class classifier, otherwise, the model is (usually) pointless.\n",
    "\n",
    "What is the majority class in the **train_data**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_positive  = (train_data['sentiment'] == +1).sum()\n",
    "num_negative = (train_data['sentiment'] == -1).sum()\n",
    "print num_positive\n",
    "print num_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the accuracy of the majority class classifier on **test_data**.\n",
    "\n",
    "**Quiz Question**: Enter the accuracy of the majority class classifier model on the **test_data**. Round your answer to two decimal places (e.g. 0.76)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_positive  = (test_data['sentiment'] == +1).sum()\n",
    "num_negative = (test_data['sentiment'] == -1).sum()\n",
    "print num_positive\n",
    "print num_negative\n",
    "print round(num_positive/len(test_data), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: Is the **sentiment_model** definitely better than the majority class classifier (the baseline)? Better 91% with train data, but with test data accuracy was 87%. Baseline accuracy from majority class classfier is 84%. So we can't say that sentiment_model is definitely better than baseline, as its accuracy is only 3% better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
